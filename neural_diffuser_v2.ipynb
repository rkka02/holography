{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d514908",
   "metadata": {},
   "source": [
    "<h1> Neural Net </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97e40d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from lucam import Lucam\n",
    "\n",
    "# --- ê¸°ë³¸ ì„¤ì • (ì´ì „ê³¼ ë™ì¼) ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "N = 600\n",
    "total_cam_roi = (450, -500, 450, -500) # Top Bottom Left Right\n",
    "first_order_cam_roi = (500, -450, 450, -500) # Top Bottom Left Right\n",
    "\n",
    "LEARNING_RATE_MODEL = 1e-3\n",
    "LEARNING_RATE_PHASE = 1e-2\n",
    "\n",
    "# --- ğŸ§  ì¤‘ê°„ ê¹Šì´ì˜ ë‰´ëŸ´ ë„¤íŠ¸ì›Œí¬ ëª¨ë¸ ì •ì˜ ---\n",
    "class MediumUNetPropagation(nn.Module):\n",
    "    def __init__(self, in_channels=2, out_channels=1):\n",
    "        super(MediumUNetPropagation, self).__init__()\n",
    "\n",
    "        # --- ì¸ì½”ë” (Contracting Path) ---\n",
    "        # Level 1\n",
    "        self.enc1 = self.conv_block(in_channels, 64)\n",
    "        # Level 2\n",
    "        self.enc2 = self.conv_block(64, 128)\n",
    "        # Level 3 (ì¶”ê°€ëœ ê¹Šì´)\n",
    "        self.enc3 = self.conv_block(128, 256)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # --- ë³‘ëª© êµ¬ê°„ (Bottleneck) ---\n",
    "        self.bottleneck = self.conv_block(256, 512)\n",
    "\n",
    "        # --- ë””ì½”ë” (Expanding Path) ---\n",
    "        # Level 3\n",
    "        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec3 = self.conv_block(256 + 256, 256) # Skip connection í¬í•¨\n",
    "        # Level 2\n",
    "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec2 = self.conv_block(128 + 128, 128) # Skip connection í¬í•¨\n",
    "        # Level 1\n",
    "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec1 = self.conv_block(64 + 64, 64)   # Skip connection í¬í•¨\n",
    "\n",
    "        # --- ìµœì¢… ì¶œë ¥ ë ˆì´ì–´ ---\n",
    "        self.out_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def conv_block(self, in_c, out_c):\n",
    "        \"\"\"ë‘ ê°œì˜ 3x3 Convì™€ ReLU, BatchNormìœ¼ë¡œ êµ¬ì„±ëœ ê¸°ë³¸ ë¸”ë¡\"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_c, out_c, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, phase_map):\n",
    "        # â€¼ï¸ ì…ë ¥ ë³€í™˜: Ï† -> [cos(Ï†), sin(Ï†)]\n",
    "        if phase_map.dim() == 3: # (B, H, W) -> (B, 1, H, W)\n",
    "            phase_map = phase_map.unsqueeze(1)\n",
    "\n",
    "        x_cos = torch.cos(phase_map)\n",
    "        x_sin = torch.sin(phase_map)\n",
    "        x = torch.cat([x_cos, x_sin], dim=1) # (B, 2, N, N)\n",
    "\n",
    "        # --- ì¸ì½”ë” ---\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool(e1))\n",
    "        e3 = self.enc3(self.pool(e2))\n",
    "\n",
    "        # --- ë³‘ëª© ---\n",
    "        b = self.bottleneck(self.pool(e3))\n",
    "\n",
    "        # --- ë””ì½”ë” + Skip Connections ---\n",
    "        d3 = self.upconv3(b)\n",
    "        d3 = torch.cat([d3, e3], dim=1)\n",
    "        d3 = self.dec3(d3)\n",
    "\n",
    "        d2 = self.upconv2(d3)\n",
    "        d2 = torch.cat([d2, e2], dim=1)\n",
    "        d2 = self.dec2(d2)\n",
    "\n",
    "        d1 = self.upconv1(d2)\n",
    "        d1 = torch.cat([d1, e1], dim=1)\n",
    "        d1 = self.dec1(d1)\n",
    "\n",
    "        # --- ì¶œë ¥ ---\n",
    "        out = self.out_conv(d1)\n",
    "        return out.squeeze(1) # (B, N, N)\n",
    "\n",
    "# --- í—¬í¼ í•¨ìˆ˜ ì •ì˜ (ì´ì „ê³¼ ë™ì¼) ---\n",
    "def save_phase_as_image(phase_tensor, filename):\n",
    "    phase_normalized = (phase_tensor.detach() + torch.pi) / (2 * torch.pi)\n",
    "    phase_uint8 = (phase_normalized * 255).byte().cpu().numpy()\n",
    "    Image.fromarray(phase_uint8).save(filename)\n",
    "\n",
    "def load_and_preprocess_image(path, size=(N, N)):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None: raise FileNotFoundError(f\"'{path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    img = cv2.resize(img, dsize=size)\n",
    "    img_float = img.astype(np.float32) / np.max(img) # 0~1 ì‚¬ì´ë¡œ ì •ê·œí™”\n",
    "    return torch.from_numpy(img_float).to('cpu')\n",
    "\n",
    "# --- ğŸŒŸ ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜ ğŸŒŸ ---\n",
    "class HolographyDataset(Dataset):\n",
    "    def __init__(self, image_dir):\n",
    "        # ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°\n",
    "        self.image_paths = glob.glob(os.path.join(image_dir, '*.jpg')) + \\\n",
    "                           glob.glob(os.path.join(image_dir, '*.png'))\n",
    "                           \n",
    "        lam = 0.532e-6\n",
    "        dx = 12.5e-6\n",
    "        z = 100e-3\n",
    "\n",
    "        lam = torch.tensor(lam).cuda()\n",
    "        dx = torch.tensor(dx).cuda()\n",
    "        z = torch.tensor(z).cuda()\n",
    "\n",
    "        # ê° ì´ë¯¸ì§€ì— ëŒ€í•œ ìœ„ìƒ í…ì„œë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬\n",
    "        self.phase_tensors = {}\n",
    "        for path in self.image_paths:\n",
    "            # ì´ˆê¸° ìœ„ìƒì€ ëœë¤ìœ¼ë¡œ ìƒì„±\n",
    "            phase = (torch.pi * torch.ones(N,N)).requires_grad_(True)\n",
    "            self.phase_tensors[path] = phase\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = self.image_paths[idx]\n",
    "        target_intensity = load_and_preprocess_image(path)\n",
    "        target_intensity = target_intensity / torch.max(target_intensity).item()\n",
    "        target_amplitude = torch.sqrt(target_intensity)\n",
    "        phase_tensor = self.phase_tensors[path]\n",
    "        return target_amplitude.to('cuda'), phase_tensor.to('cuda'), path # ê²½ë¡œë„ í•¨ê»˜ ë°˜í™˜í•˜ì—¬ ì¶”ì "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38ed97a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(44, 100):\n",
    "    pattern = np.random.rand(600, 600) * 255\n",
    "    cv2.imwrite('test.png', pattern)\n",
    "\n",
    "    slm_process = subprocess.Popen(['python', 'test.py'])\n",
    "    time.sleep(2)\n",
    "    \n",
    "    camera = Lucam()\n",
    "    capture = camera.TakeSnapshot()\n",
    "    capture = cv2.resize(capture, dsize=(600, 600))\n",
    "\n",
    "    slm_process.terminate()\n",
    "    slm_process.wait()\n",
    "    \n",
    "    cv2.imwrite(f'dataset/trainset/patterns/{i}.png', pattern)\n",
    "    cv2.imwrite(f'dataset/trainset/captures/{i}.png', capture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "996f2ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ğŸŒŸ ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜ ğŸŒŸ ---\n",
    "class SpeckleDataset(Dataset):\n",
    "    def __init__(self, pattern_dir, capture_dir):\n",
    "        # ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°\n",
    "        self.pattern_paths = sorted(glob.glob(os.path.join(pattern_dir, '*.png')))\n",
    "        self.target_paths = sorted(glob.glob(os.path.join(capture_dir, '*.png')))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pattern_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        pattern_path = self.pattern_paths[idx]\n",
    "        # 'íŒ¨í„´ ì´ë¯¸ì§€'ëŠ” 0-255 grayscaleë¡œ ì €ì¥ëœ ìœ„ìƒ ì •ë³´ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤ê³  ê°€ì •\n",
    "        pattern_img = cv2.imread(pattern_path, cv2.IMREAD_GRAYSCALE)\n",
    "        pattern_img = cv2.resize(pattern_img, dsize=(N, N))\n",
    "        \n",
    "        # 0~255 ê°’ì„ 0~2Ï€ ë²”ìœ„ì˜ ìœ„ìƒ(phase)ìœ¼ë¡œ ë³€í™˜\n",
    "        phase_map = (pattern_img.astype(np.float32) / 255.0) * 2 * np.pi\n",
    "        phase_map_tensor = torch.from_numpy(phase_map)\n",
    "\n",
    "        target_path = self.target_paths[idx]\n",
    "        target_intensity = load_and_preprocess_image(target_path)\n",
    "        target_intensity = target_intensity / torch.max(target_intensity).item()\n",
    "        target_amplitude = torch.sqrt(target_intensity)\n",
    "\n",
    "        return phase_map_tensor.to('cuda'), target_amplitude.to('cuda')\n",
    "\n",
    "# --- ë³€ìˆ˜ ë° ëª¨ë¸ ì´ˆê¸°í™” ---\n",
    "model = MediumUNetPropagation().to(device)\n",
    "\n",
    "# ğŸŒŸ ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ìƒì„±\n",
    "# 'images' í´ë”ì— í•™ìŠµìš© ì´ë¯¸ì§€ë¥¼ ë„£ì–´ì£¼ì„¸ìš”.\n",
    "train_dataset = SpeckleDataset(pattern_dir='./dataset/train/patterns',\n",
    "                               capture_dir='./dataset/train/captures')\n",
    "test_dataset = SpeckleDataset(pattern_dir='./dataset/test/patterns',\n",
    "                               capture_dir='./dataset/test/captures')\n",
    "\n",
    "# ë¯¸ë‹ˆë°°ì¹˜ í¬ê¸°. GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì ˆ.\n",
    "BATCH_SIZE = 1\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# s1, s2 ìŠ¤ì¼€ì¼ íŒ©í„°. ì´ì œ ì´ë¯¸ì§€ë§ˆë‹¤ í•„ìš”í•  ìˆ˜ ìˆìœ¼ë‚˜, ìš°ì„ ì€ ê³µìœ \n",
    "s = torch.tensor(1.0, device=device, requires_grad=True)\n",
    "\n",
    "# â€¼ï¸ ì˜µí‹°ë§ˆì´ì € ì •ì˜. ì´ì œ ìœ„ìƒ í…ì„œëŠ” ë°ì´í„°ì…‹ ì•ˆì— ìˆìœ¼ë¯€ë¡œ, ë³„ë„ë¡œ ìµœì í™”\n",
    "optimizer_model = optim.Adam(list(model.parameters()) + [s], lr=LEARNING_RATE_MODEL)\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4673bae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Epoch 1/20 ====================\n",
      "Epoch 1, Batch 1 ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Train Loss : 0.245718\n",
      "Epoch 1, Batch 11 ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Train Loss : 0.051116\n",
      "Epoch 1, Batch 21 ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Train Loss : 0.040201\n",
      "Epoch 1, Batch 31 ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Train Loss : 0.034389\n",
      "Epoch 1, Batch 41 ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Train Loss : 0.032959\n",
      "Epoch 1, Batch 51 ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Train Loss : 0.032424\n",
      "Epoch 1, Batch 61 ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Train Loss : 0.031423\n",
      "Epoch 1, Batch 71 ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Train Loss : 0.031982\n",
      "\n",
      "==================== Epoch 2/20 ====================\n",
      "Epoch 2, Batch 1 ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Train Loss : 0.031591\n",
      "Epoch 2, Batch 11 ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Train Loss : 0.031814\n",
      "Epoch 2, Batch 21 ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Train Loss : 0.031957\n",
      "Epoch 2, Batch 31 ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Train Loss : 0.031799\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# data_loaderì—ì„œ ë¯¸ë‹ˆë°°ì¹˜ ë‹¨ìœ„ë¡œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜´\u001b[39;00m\n\u001b[32m     11\u001b[39m model = model.train()\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern_amplitudes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_amplitudes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     13\u001b[39m \n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# --- ë‹¨ê³„ 1: ìœ„ìƒ ì—…ë°ì´íŠ¸ -\u001b[39;49;00m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# U-Net ëª¨ë¸ì€ ë°°ì¹˜ ì…ë ¥ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ ìˆ˜ì •ë¨\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\holo\\envs\\holo\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\holo\\envs\\holo\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\holo\\envs\\holo\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mSpeckleDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     19\u001b[39m phase_map_tensor = torch.from_numpy(phase_map)\n\u001b[32m     21\u001b[39m target_path = \u001b[38;5;28mself\u001b[39m.target_paths[idx]\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m target_intensity = \u001b[43mload_and_preprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m target_intensity = target_intensity / torch.max(target_intensity).item()\n\u001b[32m     24\u001b[39m target_amplitude = torch.sqrt(target_intensity)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 109\u001b[39m, in \u001b[36mload_and_preprocess_image\u001b[39m\u001b[34m(path, size)\u001b[39m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_and_preprocess_image\u001b[39m(path, size=(N, N)):\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m     img = \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mIMREAD_GRAYSCALE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    111\u001b[39m     img = cv2.resize(img, dsize=size)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from pytorch_msssim import ssim, ms_ssim # Multi-Scale SSIMì´ ë” ì„±ëŠ¥ì´ ì¢‹ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "import torch.nn.functional as F\n",
    "\n",
    "NUM_EPOCHS = 2 # ì „ì²´ ë°ì´í„°ì…‹ì„ ëª‡ ë²ˆ ë°˜ë³µí• ì§€\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\n{'='*20} Epoch {epoch + 1}/{NUM_EPOCHS} {'='*20}\")\n",
    "    \n",
    "    # data_loaderì—ì„œ ë¯¸ë‹ˆë°°ì¹˜ ë‹¨ìœ„ë¡œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜´\n",
    "    model = model.train()\n",
    "    for i, (pattern_amplitudes, target_amplitudes) in enumerate(train_loader):\n",
    "        \n",
    "        # --- ë‹¨ê³„ 1: ìœ„ìƒ ì—…ë°ì´íŠ¸ -\n",
    "        optimizer_model.zero_grad()\n",
    "        \n",
    "        # U-Net ëª¨ë¸ì€ ë°°ì¹˜ ì…ë ¥ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ ìˆ˜ì •ë¨\n",
    "        prediction = model(pattern_amplitudes**2)\n",
    "\n",
    "        loss_train = loss_fn(s * prediction, target_amplitudes**2)\n",
    "        loss_train.backward()\n",
    "        optimizer_model.step()\n",
    "        \n",
    "        if i%10==0:\n",
    "            print(f\"Epoch {epoch+1}, Batch {i+1} ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Train Loss : {loss_train.item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98ab18ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 Test Loss : 0.031475\n",
      "Batch 2 Test Loss : 0.031648\n",
      "Batch 3 Test Loss : 0.031562\n",
      "Batch 4 Test Loss : 0.031512\n",
      "Batch 5 Test Loss : 0.032123\n",
      "Batch 6 Test Loss : 0.031546\n",
      "Batch 7 Test Loss : 0.031795\n",
      "Batch 8 Test Loss : 0.031342\n",
      "Batch 9 Test Loss : 0.032039\n",
      "Batch 10 Test Loss : 0.032106\n",
      "Batch 11 Test Loss : 0.031734\n",
      "Batch 12 Test Loss : 0.031614\n",
      "Batch 13 Test Loss : 0.031771\n",
      "Batch 14 Test Loss : 0.031430\n",
      "Batch 15 Test Loss : 0.031634\n",
      "Batch 16 Test Loss : 0.031535\n",
      "Batch 17 Test Loss : 0.031200\n",
      "Batch 18 Test Loss : 0.032145\n",
      "Batch 19 Test Loss : 0.031499\n",
      "Batch 20 Test Loss : 0.031671\n"
     ]
    }
   ],
   "source": [
    "# data_loaderì—ì„œ ë¯¸ë‹ˆë°°ì¹˜ ë‹¨ìœ„ë¡œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜´\n",
    "model = model.eval()\n",
    "with torch.no_grad():\n",
    "    losses = []\n",
    "    for i, (pattern_amplitudes, target_amplitudes) in enumerate(test_loader):\n",
    "            \n",
    "        # U-Net ëª¨ë¸ì€ ë°°ì¹˜ ì…ë ¥ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ ìˆ˜ì •ë¨\n",
    "        prediction = model(pattern_amplitudes**2)\n",
    "\n",
    "        loss_test = loss_fn(s * prediction, target_amplitudes**2)\n",
    "\n",
    "        print(f\"Batch {i+1} Test Loss : {loss_test:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "91cc8660",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'speckle_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "812b9a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- ë³€ìˆ˜ ë° ëª¨ë¸ ì´ˆê¸°í™” ---\n",
    "model = MediumUNetPropagation().to(device)\n",
    "model.load_state_dict(torch.load('speckle_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e728169",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = Image.open('apple.png').convert('L')\n",
    "target = np.array(target)\n",
    "target = cv2.resize(target, dsize=(600,600))\n",
    "target = target / np.max(target)\n",
    "target = np.sqrt(target)\n",
    "target = torch.from_numpy(target).cuda()\n",
    "target = target.type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d68a0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase = torch.ones(600,600) * torch.pi\n",
    "phase = phase.type(torch.float32)\n",
    "phase = phase.requires_grad_()\n",
    "optimizer = torch.optim.Adam([phase], lr=1e-2)\n",
    "phase = phase.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4627a682",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\holo\\envs\\holo\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:610: UserWarning: Using a target size (torch.Size([600, 600])) that is different to the input size (torch.Size([1, 600, 600])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss : 0.367850\n",
      "Epoch 10, Loss : 0.367850\n",
      "Epoch 20, Loss : 0.367850\n",
      "Epoch 30, Loss : 0.367850\n",
      "Epoch 40, Loss : 0.367850\n",
      "Epoch 50, Loss : 0.367850\n",
      "Epoch 60, Loss : 0.367850\n",
      "Epoch 70, Loss : 0.367850\n",
      "Epoch 80, Loss : 0.367850\n",
      "Epoch 90, Loss : 0.367850\n"
     ]
    }
   ],
   "source": [
    "model = model.eval()\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    prediction = model(phase.unsqueeze(0))\n",
    "    loss = loss_fn(prediction, target**2)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i%10 == 0:\n",
    "        print(f'Epoch {i}, Loss : {loss.item():.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31c08e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase = phase.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25e58933",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase = phase / np.max(phase) * 255\n",
    "Image.fromarray(phase.astype('uint8')).save('test.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "holo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
