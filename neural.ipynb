{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d514908",
   "metadata": {},
   "source": [
    "<h1> Neural Net </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97e40d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "--- Ï¥àÍ∏∞Ìôî ÏôÑÎ£å ---\n",
      "Ï¥ù 8Í∞úÏùò Ïù¥ÎØ∏ÏßÄÎ°ú Îç∞Ïù¥ÌÑ∞ÏÖã Íµ¨ÏÑ± ÏôÑÎ£å.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from lucam import Lucam\n",
    "\n",
    "# --- Í∏∞Î≥∏ ÏÑ§Ï†ï (Ïù¥Ï†ÑÍ≥º ÎèôÏùº) ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "N = 600\n",
    "total_cam_roi = (450, -500, 450, -500) # Top Bottom Left Right\n",
    "first_order_cam_roi = (500, -450, 450, -500) # Top Bottom Left Right\n",
    "\n",
    "LEARNING_RATE_MODEL = 1e-3\n",
    "LEARNING_RATE_PHASE = 1e-2\n",
    "\n",
    "# --- üß† Ï§ëÍ∞Ñ ÍπäÏù¥Ïùò Îâ¥Îü¥ ÎÑ§Ìä∏ÏõåÌÅ¨ Î™®Îç∏ Ï†ïÏùò ---\n",
    "class MediumUNetPropagation(nn.Module):\n",
    "    def __init__(self, in_channels=2, out_channels=1):\n",
    "        super(MediumUNetPropagation, self).__init__()\n",
    "\n",
    "        # --- Ïù∏ÏΩîÎçî (Contracting Path) ---\n",
    "        # Level 1\n",
    "        self.enc1 = self.conv_block(in_channels, 64)\n",
    "        # Level 2\n",
    "        self.enc2 = self.conv_block(64, 128)\n",
    "        # Level 3 (Ï∂îÍ∞ÄÎêú ÍπäÏù¥)\n",
    "        self.enc3 = self.conv_block(128, 256)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # --- Î≥ëÎ™© Íµ¨Í∞Ñ (Bottleneck) ---\n",
    "        self.bottleneck = self.conv_block(256, 512)\n",
    "\n",
    "        # --- ÎîîÏΩîÎçî (Expanding Path) ---\n",
    "        # Level 3\n",
    "        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec3 = self.conv_block(256 + 256, 256) # Skip connection Ìè¨Ìï®\n",
    "        # Level 2\n",
    "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec2 = self.conv_block(128 + 128, 128) # Skip connection Ìè¨Ìï®\n",
    "        # Level 1\n",
    "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec1 = self.conv_block(64 + 64, 64)   # Skip connection Ìè¨Ìï®\n",
    "\n",
    "        # --- ÏµúÏ¢Ö Ï∂úÎ†• Î†àÏù¥Ïñ¥ ---\n",
    "        self.out_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def conv_block(self, in_c, out_c):\n",
    "        \"\"\"Îëê Í∞úÏùò 3x3 ConvÏôÄ ReLU, BatchNormÏúºÎ°ú Íµ¨ÏÑ±Îêú Í∏∞Î≥∏ Î∏îÎ°ù\"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_c, out_c, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, phase_map):\n",
    "        # ‚ÄºÔ∏è ÏûÖÎ†• Î≥ÄÌôò: œÜ -> [cos(œÜ), sin(œÜ)]\n",
    "        if phase_map.dim() == 3: # (B, H, W) -> (B, 1, H, W)\n",
    "            phase_map = phase_map.unsqueeze(1)\n",
    "\n",
    "        x_cos = torch.cos(phase_map)\n",
    "        x_sin = torch.sin(phase_map)\n",
    "        x = torch.cat([x_cos, x_sin], dim=1) # (B, 2, N, N)\n",
    "\n",
    "        # --- Ïù∏ÏΩîÎçî ---\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool(e1))\n",
    "        e3 = self.enc3(self.pool(e2))\n",
    "\n",
    "        # --- Î≥ëÎ™© ---\n",
    "        b = self.bottleneck(self.pool(e3))\n",
    "\n",
    "        # --- ÎîîÏΩîÎçî + Skip Connections ---\n",
    "        d3 = self.upconv3(b)\n",
    "        d3 = torch.cat([d3, e3], dim=1)\n",
    "        d3 = self.dec3(d3)\n",
    "\n",
    "        d2 = self.upconv2(d3)\n",
    "        d2 = torch.cat([d2, e2], dim=1)\n",
    "        d2 = self.dec2(d2)\n",
    "\n",
    "        d1 = self.upconv1(d2)\n",
    "        d1 = torch.cat([d1, e1], dim=1)\n",
    "        d1 = self.dec1(d1)\n",
    "\n",
    "        # --- Ï∂úÎ†• ---\n",
    "        out = self.out_conv(d1)\n",
    "        return out.squeeze(1) # (B, N, N)\n",
    "\n",
    "# --- Ìó¨Ìçº Ìï®Ïàò Ï†ïÏùò (Ïù¥Ï†ÑÍ≥º ÎèôÏùº) ---\n",
    "def save_phase_as_image(phase_tensor, filename):\n",
    "    phase_normalized = (phase_tensor.detach() + torch.pi) / (2 * torch.pi)\n",
    "    phase_uint8 = (phase_normalized * 255).byte().cpu().numpy()\n",
    "    Image.fromarray(phase_uint8).save(filename)\n",
    "\n",
    "def load_and_preprocess_image(path, size=(N, N)):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None: raise FileNotFoundError(f\"'{path}' ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.\")\n",
    "    img = cv2.resize(img, dsize=size)\n",
    "    img_float = img.astype(np.float32) / np.max(img) # 0~1 ÏÇ¨Ïù¥Î°ú Ï†ïÍ∑úÌôî\n",
    "    return torch.from_numpy(img_float).to('cpu')\n",
    "\n",
    "# --- üåü Îç∞Ïù¥ÌÑ∞ÏÖã ÌÅ¥ÎûòÏä§ Ï†ïÏùò üåü ---\n",
    "class HolographyDataset(Dataset):\n",
    "    def __init__(self, image_dir):\n",
    "        # Ïù¥ÎØ∏ÏßÄ ÌååÏùº Í≤ΩÎ°ú Î¶¨Ïä§Ìä∏ Í∞ÄÏ†∏Ïò§Í∏∞\n",
    "        self.image_paths = glob.glob(os.path.join(image_dir, '*.jpg')) + \\\n",
    "                           glob.glob(os.path.join(image_dir, '*.png'))\n",
    "                           \n",
    "        lam = 0.532e-6\n",
    "        dx = 12.5e-6\n",
    "        z = 100e-3\n",
    "\n",
    "        lam = torch.tensor(lam).cuda()\n",
    "        dx = torch.tensor(dx).cuda()\n",
    "        z = torch.tensor(z).cuda()\n",
    "\n",
    "        # Í∞Å Ïù¥ÎØ∏ÏßÄÏóê ÎåÄÌïú ÏúÑÏÉÅ ÌÖêÏÑúÎ•º Ï†ÄÏû•Ìï† ÎîïÏÖîÎÑàÎ¶¨\n",
    "        self.phase_tensors = {}\n",
    "        for path in self.image_paths:\n",
    "            # Ï¥àÍ∏∞ ÏúÑÏÉÅÏùÄ ÎûúÎç§ÏúºÎ°ú ÏÉùÏÑ±\n",
    "            phase = (torch.pi * torch.ones(N,N)).requires_grad_(True)\n",
    "            self.phase_tensors[path] = phase\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = self.image_paths[idx]\n",
    "        target_intensity = load_and_preprocess_image(path)\n",
    "        target_intensity = target_intensity / torch.max(target_intensity).item()\n",
    "        target_amplitude = torch.sqrt(target_intensity)\n",
    "        phase_tensor = self.phase_tensors[path]\n",
    "        return target_amplitude.to('cuda'), phase_tensor.to('cuda'), path # Í≤ΩÎ°úÎèÑ Ìï®Íªò Î∞òÌôòÌïòÏó¨ Ï∂îÏ†Å\n",
    "\n",
    "# --- Î≥ÄÏàò Î∞è Î™®Îç∏ Ï¥àÍ∏∞Ìôî ---\n",
    "model = MediumUNetPropagation().to(device)\n",
    "\n",
    "# üåü Îç∞Ïù¥ÌÑ∞ÏÖã Î∞è Îç∞Ïù¥ÌÑ∞Î°úÎçî ÏÉùÏÑ±\n",
    "# 'images' Ìè¥ÎçîÏóê ÌïôÏäµÏö© Ïù¥ÎØ∏ÏßÄÎ•º ÎÑ£Ïñ¥Ï£ºÏÑ∏Ïöî.\n",
    "dataset = HolographyDataset(image_dir='./images')\n",
    "# ÎØ∏ÎãàÎ∞∞Ïπò ÌÅ¨Í∏∞. GPU Î©îÎ™®Î¶¨Ïóê Îî∞Îùº Ï°∞Ï†à.\n",
    "BATCH_SIZE = 1\n",
    "data_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# s1, s2 Ïä§ÏºÄÏùº Ìå©ÌÑ∞. Ïù¥Ï†ú Ïù¥ÎØ∏ÏßÄÎßàÎã§ ÌïÑÏöîÌï† Ïàò ÏûàÏúºÎÇò, Ïö∞ÏÑ†ÏùÄ Í≥µÏú†\n",
    "s1 = torch.tensor(1.0, device=device, requires_grad=True)\n",
    "s2 = torch.tensor(1.0, device=device, requires_grad=True)\n",
    "\n",
    "# ‚ÄºÔ∏è ÏòµÌã∞ÎßàÏù¥Ï†Ä Ï†ïÏùò. Ïù¥Ï†ú ÏúÑÏÉÅ ÌÖêÏÑúÎäî Îç∞Ïù¥ÌÑ∞ÏÖã ÏïàÏóê ÏûàÏúºÎØÄÎ°ú, Î≥ÑÎèÑÎ°ú ÏµúÏ†ÅÌôî\n",
    "optimizer_model = optim.Adam(list(model.parameters()) + [s2], lr=LEARNING_RATE_MODEL)\n",
    "# ÏúÑÏÉÅ ÌÖêÏÑúÎì§ÏùÑ Î™®ÏïÑÏÑú phase ÏòµÌã∞ÎßàÏù¥Ï†ÄÏóê Îì±Î°ù\n",
    "all_phase_params = list(dataset.phase_tensors.values()) + [s1]\n",
    "optimizer_phase = optim.Adam(all_phase_params, lr=LEARNING_RATE_PHASE)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "print(f\"\\n--- Ï¥àÍ∏∞Ìôî ÏôÑÎ£å ---\")\n",
    "print(f\"Ï¥ù {len(dataset)}Í∞úÏùò Ïù¥ÎØ∏ÏßÄÎ°ú Îç∞Ïù¥ÌÑ∞ÏÖã Íµ¨ÏÑ± ÏôÑÎ£å.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08ecedfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Epoch 1/100 ====================\n",
      "Epoch 1, Batch 1 [1/2] ÏúÑÏÉÅ ÏóÖÎç∞Ïù¥Ìä∏ ÏôÑÎ£å.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     33\u001b[39m save_phase_as_image(phase_to_display, \u001b[33m'\u001b[39m\u001b[33mtest.png\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     35\u001b[39m slm_process = subprocess.Popen([\u001b[33m'\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtest.py\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# ‚ÄºÔ∏è Ïã§Ï†ú Ïπ¥Î©îÎùº Ï¥¨ÏòÅ Î°úÏßÅ\u001b[39;00m\n\u001b[32m     39\u001b[39m camera = Lucam()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from pytorch_msssim import ssim, ms_ssim # Multi-Scale SSIMÏù¥ Îçî ÏÑ±Îä•Ïù¥ Ï¢ãÏùÑ Ïàò ÏûàÏäµÎãàÎã§.\n",
    "import torch.nn.functional as F\n",
    "\n",
    "NUM_EPOCHS = 100 # Ï†ÑÏ≤¥ Îç∞Ïù¥ÌÑ∞ÏÖãÏùÑ Î™á Î≤à Î∞òÎ≥µÌï†ÏßÄ\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\n{'='*20} Epoch {epoch + 1}/{NUM_EPOCHS} {'='*20}\")\n",
    "    \n",
    "        # data_loaderÏóêÏÑú ÎØ∏ÎãàÎ∞∞Ïπò Îã®ÏúÑÎ°ú Îç∞Ïù¥ÌÑ∞Î•º Í∞ÄÏ†∏Ïò¥\n",
    "    for i, (target_amplitudes, phase_tensors, image_paths) in enumerate(data_loader):\n",
    "        \n",
    "        # --- Îã®Í≥Ñ 1: ÏúÑÏÉÅ ÏóÖÎç∞Ïù¥Ìä∏ -\n",
    "        model.eval()\n",
    "        optimizer_phase.zero_grad()\n",
    "        \n",
    "        # U-Net Î™®Îç∏ÏùÄ Î∞∞Ïπò ÏûÖÎ†•ÏùÑ Ï≤òÎ¶¨Ìï† Ïàò ÏûàÎèÑÎ°ù ÏàòÏ†ïÎê®\n",
    "        prediction_for_phase = model(phase_tensors)\n",
    "\n",
    "        loss_phase = loss_fn(s1 * prediction_for_phase, target_amplitudes**2)\n",
    "        loss_phase.backward()\n",
    "        optimizer_phase.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}, Batch {i+1} [1/2] ÏúÑÏÉÅ ÏóÖÎç∞Ïù¥Ìä∏ ÏôÑÎ£å.\")\n",
    "\n",
    "        # --- Îã®Í≥Ñ 2: Î™®Îç∏ ÏóÖÎç∞Ïù¥Ìä∏ ---\n",
    "        # Ïù¥ Îã®Í≥ÑÏóêÏÑúÎäî ÎØ∏ÎãàÎ∞∞ÏπòÏùò Í∞Å Ïù¥ÎØ∏ÏßÄÏóê ÎåÄÌï¥ Î¨ºÎ¶¨Ï†Å Ïã§ÌóòÏùÑ Î∞òÎ≥µÌï¥Ïïº Ìï®\n",
    "        \n",
    "        captured_amplitudes_batch = []\n",
    "        # Î∞∞Ïπò ÎÇ¥ Í∞Å ÏÉòÌîåÏóê ÎåÄÌï¥ SLM ÎùÑÏö∞Í≥† Ï¥¨ÏòÅ\n",
    "        for j in range(len(image_paths)):\n",
    "            phase_to_display = phase_tensors[j]\n",
    "            \n",
    "            save_phase_as_image(phase_to_display, 'test.png')\n",
    "            \n",
    "            slm_process = subprocess.Popen(['python', 'test.py'])\n",
    "            time.sleep(2)\n",
    "            \n",
    "            # ‚ÄºÔ∏è Ïã§Ï†ú Ïπ¥Î©îÎùº Ï¥¨ÏòÅ Î°úÏßÅ\n",
    "            camera = Lucam()\n",
    "            capture = camera.TakeSnapshot()\n",
    "            capture = capture[450:-500, 450:-500]\n",
    "            capture = cv2.resize(capture, dsize=(N, N))\n",
    "            cv2.imwrite('captured_image.png', capture)\n",
    "            \n",
    "            slm_process.terminate()\n",
    "            slm_process.wait()\n",
    "\n",
    "            captured_intensity = load_and_preprocess_image('captured_image.png')\n",
    "            captured_intensity = captured_intensity / torch.max(captured_intensity).item()\n",
    "            captured_amp = torch.sqrt(captured_intensity)\n",
    "            captured_amplitudes_batch.append(captured_amp)\n",
    "        \n",
    "        # Ï¥¨ÏòÅÎêú Ïù¥ÎØ∏ÏßÄÎì§ÏùÑ ÌïòÎÇòÏùò Î∞∞Ïπò ÌÖêÏÑúÎ°ú Í≤∞Ìï©\n",
    "        captured_amplitudes = torch.stack(captured_amplitudes_batch)\n",
    "        \n",
    "        # Î™®Îç∏ ÌïôÏäµ\n",
    "        model.train()\n",
    "        optimizer_model.zero_grad()\n",
    "        \n",
    "        # phase_tensorsÎäî ÏóÖÎç∞Ïù¥Ìä∏ÎêòÏóàÏßÄÎßå, Î™®Îç∏ ÌïôÏäµÏóêÎäî Ïù¥Ï†Ñ ÏÉÅÌÉúÎ•º ÏÇ¨Ïö©Ìï¥Ïïº Ìï®\n",
    "        prediction_for_model = model(phase_tensors.detach())\n",
    "\n",
    "        # loss_model = loss_fn(s2 * prediction_for_model, (captured_amplitudes**2).cuda())\n",
    "\n",
    "        loss_ssim = 1 - ssim(prediction_for_model.unsqueeze(0), (captured_amplitudes.unsqueeze(0)**2).cuda(), data_range=1.0, size_average=True)\n",
    "        loss_model = loss_ssim\n",
    "\n",
    "        loss_model.backward()\n",
    "        optimizer_model.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}, Batch {i+1} [2/2] Î™®Îç∏ ÏóÖÎç∞Ïù¥Ìä∏ ÏôÑÎ£å. Loss: {loss_model.item():.6f}\")\n",
    "        temp = phase_tensors.clone()\n",
    "        output = model(temp.detach()).detach().cpu().numpy()[0]\n",
    "        output = (output - np.min(output)) / (np.max(output) - np.min(output))\n",
    "        output = output * 255\n",
    "        Image.fromarray(output.astype('uint8')).save('output.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a886be99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2 # OpenCVÎäî Î∂ÄÎìúÎü¨Ïö¥ Í≤ΩÍ≥ÑÏÑ†ÏùÑ ÎßåÎì§Í∏∞ ÏúÑÌï¥ ÏÇ¨Ïö©Ìï©ÎãàÎã§.\n",
    "\n",
    "def create_circular_pattern_numpy(size, circle_radius, sharp=True, blur_ksize=None):\n",
    "    \"\"\"\n",
    "    NumPyÎ•º ÏÇ¨Ïö©ÌïòÏó¨ Ï§ëÏïôÏóê ÏõêÏù¥ ÏûàÎäî Ìå®ÌÑ¥ÏùÑ ÏÉùÏÑ±Ìï©ÎãàÎã§.\n",
    "\n",
    "    Args:\n",
    "        size (int): Ïù¥ÎØ∏ÏßÄÏùò Ìïú Î≥ÄÏùò ÌÅ¨Í∏∞ (N).\n",
    "        circle_radius (int): ÏõêÏùò Î∞òÏßÄÎ¶Ñ (ÌîΩÏÖÄ Îã®ÏúÑ).\n",
    "        sharp (bool, optional): TrueÏù¥Î©¥ Í≤ΩÍ≥ÑÏÑ†Ïù¥ ÎÇ†Ïπ¥Î°úÏö¥ Ïõê, FalseÏù¥Î©¥ Î∂ÄÎìúÎü¨Ïö¥ ÏõêÏùÑ ÏÉùÏÑ±.\n",
    "                                (Ïù¥ ÏòµÏÖòÏùÄ Ïù¥Ï†ú blur_ksizeÎ°ú ÎåÄÏ≤¥Îê©ÎãàÎã§.)\n",
    "        blur_ksize (int, optional): Í∞ÄÏö∞ÏãúÏïà Î∏îÎü¨ Ïª§ÎÑêÏùò ÌÅ¨Í∏∞. \n",
    "                                    NoneÏù¥ ÏïÑÎãàÎ©¥ Î∂ÄÎìúÎü¨Ïö¥ ÏõêÏùÑ ÏÉùÏÑ±Ìï©ÎãàÎã§.\n",
    "                                    ÌôÄÏàòÏó¨Ïïº ÌïòÎ©∞, ÌÅ¥ÏàòÎ°ù Í≤ΩÍ≥ÑÍ∞Ä Î∂ÄÎìúÎü¨ÏõåÏßëÎãàÎã§.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: (size, size) ÌÅ¨Í∏∞Ïùò 0Í≥º 255 ÏÇ¨Ïù¥ Í∞íÏùÑ Í∞ñÎäî uint8 Î∞∞Ïó¥ (Ïù¥ÎØ∏ÏßÄ)\n",
    "                    ÎòêÎäî 0Í≥º 1 ÏÇ¨Ïù¥ Í∞íÏùÑ Í∞ñÎäî float32 Î∞∞Ïó¥ (ÌïôÏäµÏö©).\n",
    "    \"\"\"\n",
    "    # 1. Îπà Ï∫îÎ≤ÑÏä§(Î∞∞Ïó¥) ÏÉùÏÑ±\n",
    "    pattern = np.zeros((size, size), dtype=np.float32)\n",
    "    \n",
    "    # 2. Ïù¥ÎØ∏ÏßÄÏùò Ï§ëÏã¨ Ï¢åÌëú Í≥ÑÏÇ∞\n",
    "    center_x, center_y = size // 2, size // 2\n",
    "    \n",
    "    # 3. cv2.circleÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ Ïõê Í∑∏Î¶¨Í∏∞\n",
    "    #    - ÏÉâÏÉÅ: 1.0 (float ÌÉÄÏûÖ)\n",
    "    #    - ÎëêÍªò: -1 (ÎÇ¥Î∂ÄÎ•º Ï±ÑÏõÄ)\n",
    "    cv2.circle(pattern, (center_x, center_y), circle_radius, 1.0, -1)\n",
    "    \n",
    "    # 4. (ÏÑ†ÌÉù ÏÇ¨Ìï≠) Í∞ÄÏö∞ÏãúÏïà Î∏îÎü¨Î°ú Í≤ΩÍ≥ÑÏÑ† Î∂ÄÎìúÎüΩÍ≤å ÎßåÎì§Í∏∞\n",
    "    if blur_ksize is not None and blur_ksize > 0:\n",
    "        # Ïª§ÎÑê ÌÅ¨Í∏∞Îäî ÌôÄÏàòÏó¨Ïïº Ìï®\n",
    "        if blur_ksize % 2 == 0:\n",
    "            blur_ksize += 1\n",
    "        # Í∞ÄÏö∞ÏãúÏïà Î∏îÎü¨ Ï†ÅÏö©\n",
    "        pattern = cv2.GaussianBlur(pattern, (blur_ksize, blur_ksize), 0)\n",
    "\n",
    "    return pattern\n",
    "\n",
    "\n",
    "# --- ÏÇ¨Ïö© ÏòàÏãú ---\n",
    "\n",
    "# Í∏∞Î≥∏ ÏÑ§Ï†ï\n",
    "N = 600  # Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞\n",
    "RADIUS = 50 # ÏõêÏùò Î∞òÏßÄÎ¶Ñ (ÌîΩÏÖÄ Îã®ÏúÑ)\n",
    "\n",
    "# --- 1. Í≤ΩÍ≥ÑÏÑ†Ïù¥ ÎÇ†Ïπ¥Î°úÏö¥ Ïõê ÏÉùÏÑ± ---\n",
    "sharp_circle_pattern = create_circular_pattern_numpy(\n",
    "    size=N, \n",
    "    circle_radius=RADIUS, \n",
    "    blur_ksize=None # Î∏îÎü¨Î•º Ï†ÅÏö©ÌïòÏßÄ ÏïäÏùå\n",
    ")\n",
    "\n",
    "# float Î∞∞Ïó¥ÏùÑ 0~255 uint8 Ïù¥ÎØ∏ÏßÄÎ°ú Î≥ÄÌôòÌïòÏó¨ Ï†ÄÏû•\n",
    "sharp_circle_image = (sharp_circle_pattern * 255).astype(np.uint8)\n",
    "Image.fromarray(sharp_circle_image).save(\"circle.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "holo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
