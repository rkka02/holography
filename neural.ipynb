{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d514908",
   "metadata": {},
   "source": [
    "<h1> Neural Net </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97e40d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\holo\\envs\\holo\\Lib\\site-packages\\torch\\functional.py:554: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:4316.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 초기화 완료 ---\n",
      "\n",
      "--- 초기화 완료 ---\n",
      "총 7개의 이미지로 데이터셋 구성 완료.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from lucam import Lucam\n",
    "\n",
    "# --- 기본 설정 (이전과 동일) ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "N = 600\n",
    "LEARNING_RATE_MODEL = 1e-4\n",
    "LEARNING_RATE_PHASE = 1e-3\n",
    "\n",
    "# --- 🧠 중간 깊이의 뉴럴 네트워크 모델 정의 ---\n",
    "class MediumUNetPropagation(nn.Module):\n",
    "    def __init__(self, in_channels=2, out_channels=1):\n",
    "        super(MediumUNetPropagation, self).__init__()\n",
    "\n",
    "        # --- 인코더 (Contracting Path) ---\n",
    "        # Level 1\n",
    "        self.enc1 = self.conv_block(in_channels, 64)\n",
    "        # Level 2\n",
    "        self.enc2 = self.conv_block(64, 128)\n",
    "        # Level 3 (추가된 깊이)\n",
    "        self.enc3 = self.conv_block(128, 256)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # --- 병목 구간 (Bottleneck) ---\n",
    "        self.bottleneck = self.conv_block(256, 512)\n",
    "\n",
    "        # --- 디코더 (Expanding Path) ---\n",
    "        # Level 3\n",
    "        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec3 = self.conv_block(256 + 256, 256) # Skip connection 포함\n",
    "        # Level 2\n",
    "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec2 = self.conv_block(128 + 128, 128) # Skip connection 포함\n",
    "        # Level 1\n",
    "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec1 = self.conv_block(64 + 64, 64)   # Skip connection 포함\n",
    "\n",
    "        # --- 최종 출력 레이어 ---\n",
    "        self.out_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def conv_block(self, in_c, out_c):\n",
    "        \"\"\"두 개의 3x3 Conv와 ReLU, BatchNorm으로 구성된 기본 블록\"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_c, out_c, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, phase_map):\n",
    "        # ‼️ 입력 변환: φ -> [cos(φ), sin(φ)]\n",
    "        if phase_map.dim() == 3: # (B, H, W) -> (B, 1, H, W)\n",
    "            phase_map = phase_map.unsqueeze(1)\n",
    "\n",
    "        x_cos = torch.cos(phase_map)\n",
    "        x_sin = torch.sin(phase_map)\n",
    "        x = torch.cat([x_cos, x_sin], dim=1) # (B, 2, N, N)\n",
    "\n",
    "        # --- 인코더 ---\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool(e1))\n",
    "        e3 = self.enc3(self.pool(e2))\n",
    "\n",
    "        # --- 병목 ---\n",
    "        b = self.bottleneck(self.pool(e3))\n",
    "\n",
    "        # --- 디코더 + Skip Connections ---\n",
    "        d3 = self.upconv3(b)\n",
    "        d3 = torch.cat([d3, e3], dim=1)\n",
    "        d3 = self.dec3(d3)\n",
    "\n",
    "        d2 = self.upconv2(d3)\n",
    "        d2 = torch.cat([d2, e2], dim=1)\n",
    "        d2 = self.dec2(d2)\n",
    "\n",
    "        d1 = self.upconv1(d2)\n",
    "        d1 = torch.cat([d1, e1], dim=1)\n",
    "        d1 = self.dec1(d1)\n",
    "\n",
    "        # --- 출력 ---\n",
    "        out = self.out_conv(d1)\n",
    "        return out.squeeze(1) # (B, N, N)\n",
    "\n",
    "# --- 헬퍼 함수 정의 (이전과 동일) ---\n",
    "def save_phase_as_image(phase_tensor, filename):\n",
    "    phase_normalized = (phase_tensor.detach() + torch.pi) / (2 * torch.pi)\n",
    "    phase_uint8 = (phase_normalized * 255).byte().cpu().numpy()\n",
    "    Image.fromarray(phase_uint8).save(filename)\n",
    "\n",
    "def load_and_preprocess_image(path, size=(N, N)):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None: raise FileNotFoundError(f\"'{path}' 파일을 찾을 수 없습니다.\")\n",
    "    img = cv2.resize(img, dsize=size)\n",
    "    img_float = img.astype(np.float32) / np.max(img) # 0~1 사이로 정규화\n",
    "    return torch.from_numpy(img_float).to('cpu')\n",
    "\n",
    "def fresnel_cuda(image, lam, dx, z):\n",
    "    N = 600\n",
    "    L = N * dx\n",
    "\n",
    "    x = torch.linspace(-L/2, L/2, N).cuda()\n",
    "    y = x\n",
    "    X, Y = torch.meshgrid(x, y)\n",
    "\n",
    "    k = 2 * torch.pi / lam\n",
    "    k = k.cuda()\n",
    "\n",
    "    coeff = torch.exp(1j * k * z) / (1j * lam * z)\n",
    "    kernel = coeff * torch.exp(1j * k / 2 / z * (X**2 + Y**2))\n",
    "    transfer = torch.fft.fftshift(torch.fft.fft2(kernel))\n",
    "\n",
    "    f_image = torch.fft.fftshift(torch.fft.fft2(image))\n",
    "    f_image = f_image * transfer\n",
    "    image = torch.fft.ifft2(torch.fft.ifftshift(f_image))\n",
    "    image = torch.fft.fftshift(image) # Don't know why do this but this should be exist\n",
    "    return image\n",
    "\n",
    "# --- 🌟 데이터셋 클래스 정의 🌟 ---\n",
    "class HolographyDataset(Dataset):\n",
    "    def __init__(self, image_dir):\n",
    "        # 이미지 파일 경로 리스트 가져오기\n",
    "        self.image_paths = glob.glob(os.path.join(image_dir, '*.jpg')) + \\\n",
    "                           glob.glob(os.path.join(image_dir, '*.png'))\n",
    "                           \n",
    "        lam = 0.532e-6\n",
    "        dx = 12.5e-6\n",
    "        z = 100e-3\n",
    "\n",
    "        lam = torch.tensor(lam).cuda()\n",
    "        dx = torch.tensor(dx).cuda()\n",
    "        z = torch.tensor(z).cuda()\n",
    "\n",
    "        # 각 이미지에 대한 위상 텐서를 저장할 딕셔너리\n",
    "        self.phase_tensors = {}\n",
    "        for path in self.image_paths:\n",
    "            # 초기 위상은 랜덤으로 생성\n",
    "            target_intensity = load_and_preprocess_image(path)\n",
    "            target_amplitude = torch.sqrt(target_intensity).cuda()\n",
    "            field = fresnel_cuda(target_amplitude, lam, dx, -z)\n",
    "            phase = torch.angle(field).requires_grad_(True)\n",
    "            self.phase_tensors[path] = phase\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = self.image_paths[idx]\n",
    "        target_intensity = load_and_preprocess_image(path)\n",
    "        target_amplitude = torch.sqrt(target_intensity)\n",
    "        phase_tensor = self.phase_tensors[path]\n",
    "        return target_amplitude.to('cuda'), phase_tensor.to('cuda'), path # 경로도 함께 반환하여 추적\n",
    "\n",
    "# --- 변수 및 모델 초기화 ---\n",
    "model = MediumUNetPropagation().to(device)\n",
    "\n",
    "# 🌟 데이터셋 및 데이터로더 생성\n",
    "# 'images' 폴더에 학습용 이미지를 넣어주세요.\n",
    "dataset = HolographyDataset(image_dir='./images')\n",
    "# 미니배치 크기. GPU 메모리에 따라 조절.\n",
    "BATCH_SIZE = 1\n",
    "data_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# s1, s2 스케일 팩터. 이제 이미지마다 필요할 수 있으나, 우선은 공유\n",
    "s1 = torch.tensor(1.0, device=device, requires_grad=True)\n",
    "s2 = torch.tensor(1.0, device=device, requires_grad=True)\n",
    "\n",
    "# ‼️ 옵티마이저 정의. 이제 위상 텐서는 데이터셋 안에 있으므로, 별도로 최적화\n",
    "optimizer_model = optim.Adam(list(model.parameters()) + [s2], lr=LEARNING_RATE_MODEL)\n",
    "# 위상 텐서들을 모아서 phase 옵티마이저에 등록\n",
    "all_phase_params = list(dataset.phase_tensors.values()) + [s1]\n",
    "optimizer_phase = optim.Adam(all_phase_params, lr=LEARNING_RATE_PHASE)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "print(f\"\\n--- 초기화 완료 ---\")\n",
    "print(f\"\\n--- 초기화 완료 ---\")\n",
    "print(f\"총 {len(dataset)}개의 이미지로 데이터셋 구성 완료.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298bb775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‼️ 옵티마이저 정의. 이제 위상 텐서는 데이터셋 안에 있으므로, 별도로 최적화\n",
    "optimizer_model = optim.Adam(list(model.parameters()) + [s2], lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08ecedfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Epoch 1/15 ====================\n",
      "Epoch 1, Batch 1 [1/2] 위상 업데이트 완료. Loss: 0.022373\n",
      "Epoch 1, Batch 1 [2/2] 모델 업데이트 완료.\n",
      "Epoch 1, Batch 2 [1/2] 위상 업데이트 완료. Loss: 0.065856\n",
      "Epoch 1, Batch 2 [2/2] 모델 업데이트 완료.\n",
      "Epoch 1, Batch 3 [1/2] 위상 업데이트 완료. Loss: 0.056265\n",
      "Epoch 1, Batch 3 [2/2] 모델 업데이트 완료.\n",
      "Epoch 1, Batch 4 [1/2] 위상 업데이트 완료. Loss: 0.132284\n",
      "Epoch 1, Batch 4 [2/2] 모델 업데이트 완료.\n",
      "Epoch 1, Batch 5 [1/2] 위상 업데이트 완료. Loss: 0.089095\n",
      "Epoch 1, Batch 5 [2/2] 모델 업데이트 완료.\n",
      "Epoch 1, Batch 6 [1/2] 위상 업데이트 완료. Loss: 0.038387\n",
      "Epoch 1, Batch 6 [2/2] 모델 업데이트 완료.\n",
      "Epoch 1, Batch 7 [1/2] 위상 업데이트 완료. Loss: 0.034121\n",
      "Epoch 1, Batch 7 [2/2] 모델 업데이트 완료.\n",
      "\n",
      "==================== Epoch 2/15 ====================\n",
      "Epoch 2, Batch 1 [1/2] 위상 업데이트 완료. Loss: 0.019435\n",
      "Epoch 2, Batch 1 [2/2] 모델 업데이트 완료.\n",
      "Epoch 2, Batch 2 [1/2] 위상 업데이트 완료. Loss: 0.065524\n",
      "Epoch 2, Batch 2 [2/2] 모델 업데이트 완료.\n",
      "Epoch 2, Batch 3 [1/2] 위상 업데이트 완료. Loss: 0.032131\n",
      "Epoch 2, Batch 3 [2/2] 모델 업데이트 완료.\n",
      "Epoch 2, Batch 4 [1/2] 위상 업데이트 완료. Loss: 0.058664\n",
      "Epoch 2, Batch 4 [2/2] 모델 업데이트 완료.\n",
      "Epoch 2, Batch 5 [1/2] 위상 업데이트 완료. Loss: 0.055240\n",
      "Epoch 2, Batch 5 [2/2] 모델 업데이트 완료.\n",
      "Epoch 2, Batch 6 [1/2] 위상 업데이트 완료. Loss: 0.027724\n",
      "Epoch 2, Batch 6 [2/2] 모델 업데이트 완료.\n",
      "Epoch 2, Batch 7 [1/2] 위상 업데이트 완료. Loss: 0.046988\n",
      "Epoch 2, Batch 7 [2/2] 모델 업데이트 완료.\n",
      "\n",
      "==================== Epoch 3/15 ====================\n",
      "Epoch 3, Batch 1 [1/2] 위상 업데이트 완료. Loss: 0.045398\n",
      "Epoch 3, Batch 1 [2/2] 모델 업데이트 완료.\n",
      "Epoch 3, Batch 2 [1/2] 위상 업데이트 완료. Loss: 0.083459\n",
      "Epoch 3, Batch 2 [2/2] 모델 업데이트 완료.\n",
      "Epoch 3, Batch 3 [1/2] 위상 업데이트 완료. Loss: 0.044907\n",
      "Epoch 3, Batch 3 [2/2] 모델 업데이트 완료.\n",
      "Epoch 3, Batch 4 [1/2] 위상 업데이트 완료. Loss: 0.035890\n",
      "Epoch 3, Batch 4 [2/2] 모델 업데이트 완료.\n",
      "Epoch 3, Batch 5 [1/2] 위상 업데이트 완료. Loss: 0.062454\n",
      "Epoch 3, Batch 5 [2/2] 모델 업데이트 완료.\n",
      "Epoch 3, Batch 6 [1/2] 위상 업데이트 완료. Loss: 0.085972\n",
      "Epoch 3, Batch 6 [2/2] 모델 업데이트 완료.\n",
      "Epoch 3, Batch 7 [1/2] 위상 업데이트 완료. Loss: 0.125628\n",
      "Epoch 3, Batch 7 [2/2] 모델 업데이트 완료.\n",
      "\n",
      "==================== Epoch 4/15 ====================\n",
      "Epoch 4, Batch 1 [1/2] 위상 업데이트 완료. Loss: 0.032503\n",
      "Epoch 4, Batch 1 [2/2] 모델 업데이트 완료.\n",
      "Epoch 4, Batch 2 [1/2] 위상 업데이트 완료. Loss: 0.108616\n",
      "Epoch 4, Batch 2 [2/2] 모델 업데이트 완료.\n",
      "Epoch 4, Batch 3 [1/2] 위상 업데이트 완료. Loss: 0.094939\n",
      "Epoch 4, Batch 3 [2/2] 모델 업데이트 완료.\n",
      "Epoch 4, Batch 4 [1/2] 위상 업데이트 완료. Loss: 0.135647\n",
      "Epoch 4, Batch 4 [2/2] 모델 업데이트 완료.\n",
      "Epoch 4, Batch 5 [1/2] 위상 업데이트 완료. Loss: 0.095661\n",
      "Epoch 4, Batch 5 [2/2] 모델 업데이트 완료.\n",
      "Epoch 4, Batch 6 [1/2] 위상 업데이트 완료. Loss: 0.048363\n",
      "Epoch 4, Batch 6 [2/2] 모델 업데이트 완료.\n",
      "Epoch 4, Batch 7 [1/2] 위상 업데이트 완료. Loss: 0.150413\n",
      "Epoch 4, Batch 7 [2/2] 모델 업데이트 완료.\n",
      "\n",
      "==================== Epoch 5/15 ====================\n",
      "Epoch 5, Batch 1 [1/2] 위상 업데이트 완료. Loss: 0.115471\n",
      "Epoch 5, Batch 1 [2/2] 모델 업데이트 완료.\n",
      "Epoch 5, Batch 2 [1/2] 위상 업데이트 완료. Loss: 0.075649\n",
      "Epoch 5, Batch 2 [2/2] 모델 업데이트 완료.\n",
      "Epoch 5, Batch 3 [1/2] 위상 업데이트 완료. Loss: 0.093131\n",
      "Epoch 5, Batch 3 [2/2] 모델 업데이트 완료.\n",
      "Epoch 5, Batch 4 [1/2] 위상 업데이트 완료. Loss: 0.133600\n",
      "Epoch 5, Batch 4 [2/2] 모델 업데이트 완료.\n",
      "Epoch 5, Batch 5 [1/2] 위상 업데이트 완료. Loss: 0.033066\n",
      "Epoch 5, Batch 5 [2/2] 모델 업데이트 완료.\n",
      "Epoch 5, Batch 6 [1/2] 위상 업데이트 완료. Loss: 0.044808\n",
      "Epoch 5, Batch 6 [2/2] 모델 업데이트 완료.\n",
      "Epoch 5, Batch 7 [1/2] 위상 업데이트 완료. Loss: 0.118147\n",
      "Epoch 5, Batch 7 [2/2] 모델 업데이트 완료.\n",
      "\n",
      "==================== Epoch 6/15 ====================\n",
      "Epoch 6, Batch 1 [1/2] 위상 업데이트 완료. Loss: 0.033464\n",
      "Epoch 6, Batch 1 [2/2] 모델 업데이트 완료.\n",
      "Epoch 6, Batch 2 [1/2] 위상 업데이트 완료. Loss: 0.070910\n",
      "Epoch 6, Batch 2 [2/2] 모델 업데이트 완료.\n",
      "Epoch 6, Batch 3 [1/2] 위상 업데이트 완료. Loss: 0.106536\n",
      "Epoch 6, Batch 3 [2/2] 모델 업데이트 완료.\n",
      "Epoch 6, Batch 4 [1/2] 위상 업데이트 완료. Loss: 0.086083\n",
      "Epoch 6, Batch 4 [2/2] 모델 업데이트 완료.\n",
      "Epoch 6, Batch 5 [1/2] 위상 업데이트 완료. Loss: 0.111469\n",
      "Epoch 6, Batch 5 [2/2] 모델 업데이트 완료.\n",
      "Epoch 6, Batch 6 [1/2] 위상 업데이트 완료. Loss: 0.062918\n",
      "Epoch 6, Batch 6 [2/2] 모델 업데이트 완료.\n",
      "Epoch 6, Batch 7 [1/2] 위상 업데이트 완료. Loss: 0.041588\n",
      "Epoch 6, Batch 7 [2/2] 모델 업데이트 완료.\n",
      "\n",
      "==================== Epoch 7/15 ====================\n",
      "Epoch 7, Batch 1 [1/2] 위상 업데이트 완료. Loss: 0.032487\n",
      "Epoch 7, Batch 1 [2/2] 모델 업데이트 완료.\n",
      "Epoch 7, Batch 2 [1/2] 위상 업데이트 완료. Loss: 0.043591\n",
      "Epoch 7, Batch 2 [2/2] 모델 업데이트 완료.\n",
      "Epoch 7, Batch 3 [1/2] 위상 업데이트 완료. Loss: 0.068316\n",
      "Epoch 7, Batch 3 [2/2] 모델 업데이트 완료.\n",
      "Epoch 7, Batch 4 [1/2] 위상 업데이트 완료. Loss: 0.109601\n",
      "Epoch 7, Batch 4 [2/2] 모델 업데이트 완료.\n",
      "Epoch 7, Batch 5 [1/2] 위상 업데이트 완료. Loss: 0.064238\n",
      "Epoch 7, Batch 5 [2/2] 모델 업데이트 완료.\n",
      "Epoch 7, Batch 6 [1/2] 위상 업데이트 완료. Loss: 0.064028\n",
      "Epoch 7, Batch 6 [2/2] 모델 업데이트 완료.\n",
      "Epoch 7, Batch 7 [1/2] 위상 업데이트 완료. Loss: 0.106791\n",
      "Epoch 7, Batch 7 [2/2] 모델 업데이트 완료.\n",
      "\n",
      "==================== Epoch 8/15 ====================\n",
      "Epoch 8, Batch 1 [1/2] 위상 업데이트 완료. Loss: 0.060581\n",
      "Epoch 8, Batch 1 [2/2] 모델 업데이트 완료.\n",
      "Epoch 8, Batch 2 [1/2] 위상 업데이트 완료. Loss: 0.053138\n",
      "Epoch 8, Batch 2 [2/2] 모델 업데이트 완료.\n",
      "Epoch 8, Batch 3 [1/2] 위상 업데이트 완료. Loss: 0.108632\n",
      "Epoch 8, Batch 3 [2/2] 모델 업데이트 완료.\n",
      "Epoch 8, Batch 4 [1/2] 위상 업데이트 완료. Loss: 0.038877\n",
      "Epoch 8, Batch 4 [2/2] 모델 업데이트 완료.\n",
      "Epoch 8, Batch 5 [1/2] 위상 업데이트 완료. Loss: 0.095221\n",
      "Epoch 8, Batch 5 [2/2] 모델 업데이트 완료.\n",
      "Epoch 8, Batch 6 [1/2] 위상 업데이트 완료. Loss: 0.071071\n",
      "Epoch 8, Batch 6 [2/2] 모델 업데이트 완료.\n",
      "Epoch 8, Batch 7 [1/2] 위상 업데이트 완료. Loss: 0.038562\n",
      "Epoch 8, Batch 7 [2/2] 모델 업데이트 완료.\n",
      "\n",
      "==================== Epoch 9/15 ====================\n",
      "Epoch 9, Batch 1 [1/2] 위상 업데이트 완료. Loss: 0.047880\n",
      "Epoch 9, Batch 1 [2/2] 모델 업데이트 완료.\n",
      "Epoch 9, Batch 2 [1/2] 위상 업데이트 완료. Loss: 0.039079\n",
      "Epoch 9, Batch 2 [2/2] 모델 업데이트 완료.\n",
      "Epoch 9, Batch 3 [1/2] 위상 업데이트 완료. Loss: 0.107223\n",
      "Epoch 9, Batch 3 [2/2] 모델 업데이트 완료.\n",
      "Epoch 9, Batch 4 [1/2] 위상 업데이트 완료. Loss: 0.061533\n",
      "Epoch 9, Batch 4 [2/2] 모델 업데이트 완료.\n",
      "Epoch 9, Batch 5 [1/2] 위상 업데이트 완료. Loss: 0.068095\n",
      "Epoch 9, Batch 5 [2/2] 모델 업데이트 완료.\n",
      "Epoch 9, Batch 6 [1/2] 위상 업데이트 완료. Loss: 0.035450\n",
      "Epoch 9, Batch 6 [2/2] 모델 업데이트 완료.\n",
      "Epoch 9, Batch 7 [1/2] 위상 업데이트 완료. Loss: 0.096409\n",
      "Epoch 9, Batch 7 [2/2] 모델 업데이트 완료.\n",
      "\n",
      "==================== Epoch 10/15 ====================\n",
      "Epoch 10, Batch 1 [1/2] 위상 업데이트 완료. Loss: 0.062785\n",
      "Epoch 10, Batch 1 [2/2] 모델 업데이트 완료.\n",
      "Epoch 10, Batch 2 [1/2] 위상 업데이트 완료. Loss: 0.067094\n",
      "Epoch 10, Batch 2 [2/2] 모델 업데이트 완료.\n",
      "Epoch 10, Batch 3 [1/2] 위상 업데이트 완료. Loss: 0.032994\n",
      "Epoch 10, Batch 3 [2/2] 모델 업데이트 완료.\n",
      "Epoch 10, Batch 4 [1/2] 위상 업데이트 완료. Loss: 0.095104\n",
      "Epoch 10, Batch 4 [2/2] 모델 업데이트 완료.\n",
      "Epoch 10, Batch 5 [1/2] 위상 업데이트 완료. Loss: 0.090300\n",
      "Epoch 10, Batch 5 [2/2] 모델 업데이트 완료.\n",
      "Epoch 10, Batch 6 [1/2] 위상 업데이트 완료. Loss: 0.044740\n",
      "Epoch 10, Batch 6 [2/2] 모델 업데이트 완료.\n",
      "Epoch 10, Batch 7 [1/2] 위상 업데이트 완료. Loss: 0.035774\n",
      "Epoch 10, Batch 7 [2/2] 모델 업데이트 완료.\n",
      "\n",
      "==================== Epoch 11/15 ====================\n",
      "Epoch 11, Batch 1 [1/2] 위상 업데이트 완료. Loss: 0.032212\n",
      "Epoch 11, Batch 1 [2/2] 모델 업데이트 완료.\n",
      "Epoch 11, Batch 2 [1/2] 위상 업데이트 완료. Loss: 0.033913\n",
      "Epoch 11, Batch 2 [2/2] 모델 업데이트 완료.\n",
      "Epoch 11, Batch 3 [1/2] 위상 업데이트 완료. Loss: 0.092810\n",
      "Epoch 11, Batch 3 [2/2] 모델 업데이트 완료.\n",
      "Epoch 11, Batch 4 [1/2] 위상 업데이트 완료. Loss: 0.085376\n",
      "Epoch 11, Batch 4 [2/2] 모델 업데이트 완료.\n",
      "Epoch 11, Batch 5 [1/2] 위상 업데이트 완료. Loss: 0.064328\n",
      "Epoch 11, Batch 5 [2/2] 모델 업데이트 완료.\n",
      "Epoch 11, Batch 6 [1/2] 위상 업데이트 완료. Loss: 0.062619\n",
      "Epoch 11, Batch 6 [2/2] 모델 업데이트 완료.\n",
      "Epoch 11, Batch 7 [1/2] 위상 업데이트 완료. Loss: 0.040872\n",
      "Epoch 11, Batch 7 [2/2] 모델 업데이트 완료.\n",
      "\n",
      "==================== Epoch 12/15 ====================\n",
      "Epoch 12, Batch 1 [1/2] 위상 업데이트 완료. Loss: 0.091143\n",
      "Epoch 12, Batch 1 [2/2] 모델 업데이트 완료.\n",
      "Epoch 12, Batch 2 [1/2] 위상 업데이트 완료. Loss: 0.071950\n",
      "Epoch 12, Batch 2 [2/2] 모델 업데이트 완료.\n",
      "Epoch 12, Batch 3 [1/2] 위상 업데이트 완료. Loss: 0.037524\n",
      "Epoch 12, Batch 3 [2/2] 모델 업데이트 완료.\n",
      "Epoch 12, Batch 4 [1/2] 위상 업데이트 완료. Loss: 0.032357\n",
      "Epoch 12, Batch 4 [2/2] 모델 업데이트 완료.\n",
      "Epoch 12, Batch 5 [1/2] 위상 업데이트 완료. Loss: 0.083861\n",
      "Epoch 12, Batch 5 [2/2] 모델 업데이트 완료.\n",
      "Epoch 12, Batch 6 [1/2] 위상 업데이트 완료. Loss: 0.064674\n",
      "Epoch 12, Batch 6 [2/2] 모델 업데이트 완료.\n",
      "Epoch 12, Batch 7 [1/2] 위상 업데이트 완료. Loss: 0.038995\n",
      "Epoch 12, Batch 7 [2/2] 모델 업데이트 완료.\n",
      "\n",
      "==================== Epoch 13/15 ====================\n",
      "Epoch 13, Batch 1 [1/2] 위상 업데이트 완료. Loss: 0.035872\n",
      "Epoch 13, Batch 1 [2/2] 모델 업데이트 완료.\n",
      "Epoch 13, Batch 2 [1/2] 위상 업데이트 완료. Loss: 0.074475\n",
      "Epoch 13, Batch 2 [2/2] 모델 업데이트 완료.\n",
      "Epoch 13, Batch 3 [1/2] 위상 업데이트 완료. Loss: 0.039508\n",
      "Epoch 13, Batch 3 [2/2] 모델 업데이트 완료.\n",
      "Epoch 13, Batch 4 [1/2] 위상 업데이트 완료. Loss: 0.062479\n",
      "Epoch 13, Batch 4 [2/2] 모델 업데이트 완료.\n",
      "Epoch 13, Batch 5 [1/2] 위상 업데이트 완료. Loss: 0.095753\n",
      "Epoch 13, Batch 5 [2/2] 모델 업데이트 완료.\n",
      "Epoch 13, Batch 6 [1/2] 위상 업데이트 완료. Loss: 0.035079\n",
      "Epoch 13, Batch 6 [2/2] 모델 업데이트 완료.\n",
      "Epoch 13, Batch 7 [1/2] 위상 업데이트 완료. Loss: 0.096380\n",
      "Epoch 13, Batch 7 [2/2] 모델 업데이트 완료.\n",
      "\n",
      "==================== Epoch 14/15 ====================\n",
      "Epoch 14, Batch 1 [1/2] 위상 업데이트 완료. Loss: 0.097383\n",
      "Epoch 14, Batch 1 [2/2] 모델 업데이트 완료.\n",
      "Epoch 14, Batch 2 [1/2] 위상 업데이트 완료. Loss: 0.034780\n",
      "Epoch 14, Batch 2 [2/2] 모델 업데이트 완료.\n",
      "Epoch 14, Batch 3 [1/2] 위상 업데이트 완료. Loss: 0.081735\n",
      "Epoch 14, Batch 3 [2/2] 모델 업데이트 완료.\n",
      "Epoch 14, Batch 4 [1/2] 위상 업데이트 완료. Loss: 0.109297\n",
      "Epoch 14, Batch 4 [2/2] 모델 업데이트 완료.\n",
      "Epoch 14, Batch 5 [1/2] 위상 업데이트 완료. Loss: 0.057384\n",
      "Epoch 14, Batch 5 [2/2] 모델 업데이트 완료.\n",
      "Epoch 14, Batch 6 [1/2] 위상 업데이트 완료. Loss: 0.148094\n",
      "Epoch 14, Batch 6 [2/2] 모델 업데이트 완료.\n",
      "Epoch 14, Batch 7 [1/2] 위상 업데이트 완료. Loss: 0.037313\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 48\u001b[39m\n\u001b[32m     45\u001b[39m save_phase_as_image(phase_to_display, \u001b[33m'\u001b[39m\u001b[33mtest.png\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     47\u001b[39m slm_process = subprocess.Popen([\u001b[33m'\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtest.py\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# ‼️ 실제 카메라 촬영 로직\u001b[39;00m\n\u001b[32m     51\u001b[39m camera = Lucam()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from pytorch_msssim import ssim, ms_ssim # Multi-Scale SSIM이 더 성능이 좋을 수 있습니다.\n",
    "import torch.nn.functional as F\n",
    "\n",
    "NUM_EPOCHS = 15 # 전체 데이터셋을 몇 번 반복할지\n",
    "lam = 0.532e-6\n",
    "dx = 12.5e-6\n",
    "z = 100e-3\n",
    "\n",
    "lam = torch.tensor(lam).cuda()\n",
    "dx = torch.tensor(dx).cuda()\n",
    "z = torch.tensor(z).cuda()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\n{'='*20} Epoch {epoch + 1}/{NUM_EPOCHS} {'='*20}\")\n",
    "    \n",
    "        # data_loader에서 미니배치 단위로 데이터를 가져옴\n",
    "    for i, (target_amplitudes, phase_tensors, image_paths) in enumerate(data_loader):\n",
    "        \n",
    "        # --- 단계 1: 위상 업데이트 -\n",
    "        model.eval()\n",
    "        optimizer_phase.zero_grad()\n",
    "        \n",
    "        # U-Net 모델은 배치 입력을 처리할 수 있도록 수정됨\n",
    "        prediction_for_phase = model(phase_tensors)\n",
    "\n",
    "        field = torch.exp(1j * prediction_for_phase)\n",
    "        propagated_field = fresnel_cuda(field, lam, dx, z)\n",
    "        prediction_for_phase = torch.abs(propagated_field)\n",
    "        prediction_for_phase = prediction_for_phase/torch.max(prediction_for_phase).item()\n",
    "\n",
    "        loss_phase = loss_fn(s1 * prediction_for_phase, target_amplitudes)\n",
    "        loss_phase.backward()\n",
    "        optimizer_phase.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}, Batch {i+1} [1/2] 위상 업데이트 완료. Loss: {loss_phase.item():.6f}\")\n",
    "\n",
    "        # --- 단계 2: 모델 업데이트 ---\n",
    "        # 이 단계에서는 미니배치의 각 이미지에 대해 물리적 실험을 반복해야 함\n",
    "        \n",
    "        captured_amplitudes_batch = []\n",
    "        # 배치 내 각 샘플에 대해 SLM 띄우고 촬영\n",
    "        for j in range(len(image_paths)):\n",
    "            phase_to_display = phase_tensors[j]\n",
    "            \n",
    "            save_phase_as_image(phase_to_display, 'test.png')\n",
    "            \n",
    "            slm_process = subprocess.Popen(['python', 'test.py'])\n",
    "            time.sleep(2)\n",
    "            \n",
    "            # ‼️ 실제 카메라 촬영 로직\n",
    "            camera = Lucam()\n",
    "            capture = camera.TakeSnapshot()\n",
    "            capture = cv2.resize(capture, dsize=(N, N))\n",
    "            cv2.imwrite('captured_image.png', capture)\n",
    "            \n",
    "            slm_process.terminate()\n",
    "            slm_process.wait()\n",
    "\n",
    "            captured_amp = torch.sqrt(load_and_preprocess_image('captured_image.png'))\n",
    "            captured_amplitudes_batch.append(captured_amp)\n",
    "        \n",
    "        # 촬영된 이미지들을 하나의 배치 텐서로 결합\n",
    "        captured_amplitudes = torch.stack(captured_amplitudes_batch)\n",
    "        \n",
    "        # 모델 학습\n",
    "        model.train()\n",
    "        optimizer_model.zero_grad()\n",
    "        \n",
    "        # phase_tensors는 업데이트되었지만, 모델 학습에는 이전 상태를 사용해야 함\n",
    "        prediction_for_model = model(phase_tensors.detach())\n",
    "\n",
    "        field = torch.exp(1j * prediction_for_model)\n",
    "        propagated_field = fresnel_cuda(field, lam, dx, z)\n",
    "        prediction_for_model = torch.abs(propagated_field)\n",
    "        prediction_for_model = prediction_for_model / torch.max(prediction_for_model).item()\n",
    "\n",
    "        loss_model = loss_fn(s2 * prediction_for_model, captured_amplitudes.cuda())\n",
    "        loss_model.backward()\n",
    "        optimizer_model.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}, Batch {i+1} [2/2] 모델 업데이트 완료.\")\n",
    "        temp = phase_tensors.clone()\n",
    "        output = model(temp.detach()).detach().cpu().numpy()[0]\n",
    "        output = (output - np.min(output)) / (np.max(output) - np.min(output))\n",
    "        output = output * 255\n",
    "        Image.fromarray(output.astype('uint8')).save('output.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "holo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
