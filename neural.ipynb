{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d514908",
   "metadata": {},
   "source": [
    "<h1> Neural Net </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97e40d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\holo\\envs\\holo\\Lib\\site-packages\\torch\\functional.py:554: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:4316.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ì´ˆê¸°í™” ì™„ë£Œ ---\n",
      "\n",
      "--- ì´ˆê¸°í™” ì™„ë£Œ ---\n",
      "ì´ 7ê°œì˜ ì´ë¯¸ì§€ë¡œ ë°ì´í„°ì…‹ êµ¬ì„± ì™„ë£Œ.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from lucam import Lucam\n",
    "\n",
    "# --- ê¸°ë³¸ ì„¤ì • (ì´ì „ê³¼ ë™ì¼) ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "N = 600\n",
    "LEARNING_RATE_MODEL = 1e-4\n",
    "LEARNING_RATE_PHASE = 1e-3\n",
    "\n",
    "# --- ğŸ§  ì¤‘ê°„ ê¹Šì´ì˜ ë‰´ëŸ´ ë„¤íŠ¸ì›Œí¬ ëª¨ë¸ ì •ì˜ ---\n",
    "class MediumUNetPropagation(nn.Module):\n",
    "    def __init__(self, in_channels=2, out_channels=1):\n",
    "        super(MediumUNetPropagation, self).__init__()\n",
    "\n",
    "        # --- ì¸ì½”ë” (Contracting Path) ---\n",
    "        # Level 1\n",
    "        self.enc1 = self.conv_block(in_channels, 64)\n",
    "        # Level 2\n",
    "        self.enc2 = self.conv_block(64, 128)\n",
    "        # Level 3 (ì¶”ê°€ëœ ê¹Šì´)\n",
    "        self.enc3 = self.conv_block(128, 256)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # --- ë³‘ëª© êµ¬ê°„ (Bottleneck) ---\n",
    "        self.bottleneck = self.conv_block(256, 512)\n",
    "\n",
    "        # --- ë””ì½”ë” (Expanding Path) ---\n",
    "        # Level 3\n",
    "        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec3 = self.conv_block(256 + 256, 256) # Skip connection í¬í•¨\n",
    "        # Level 2\n",
    "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec2 = self.conv_block(128 + 128, 128) # Skip connection í¬í•¨\n",
    "        # Level 1\n",
    "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec1 = self.conv_block(64 + 64, 64)   # Skip connection í¬í•¨\n",
    "\n",
    "        # --- ìµœì¢… ì¶œë ¥ ë ˆì´ì–´ ---\n",
    "        self.out_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def conv_block(self, in_c, out_c):\n",
    "        \"\"\"ë‘ ê°œì˜ 3x3 Convì™€ ReLU, BatchNormìœ¼ë¡œ êµ¬ì„±ëœ ê¸°ë³¸ ë¸”ë¡\"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_c, out_c, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, phase_map):\n",
    "        # â€¼ï¸ ì…ë ¥ ë³€í™˜: Ï† -> [cos(Ï†), sin(Ï†)]\n",
    "        if phase_map.dim() == 3: # (B, H, W) -> (B, 1, H, W)\n",
    "            phase_map = phase_map.unsqueeze(1)\n",
    "\n",
    "        x_cos = torch.cos(phase_map)\n",
    "        x_sin = torch.sin(phase_map)\n",
    "        x = torch.cat([x_cos, x_sin], dim=1) # (B, 2, N, N)\n",
    "\n",
    "        # --- ì¸ì½”ë” ---\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool(e1))\n",
    "        e3 = self.enc3(self.pool(e2))\n",
    "\n",
    "        # --- ë³‘ëª© ---\n",
    "        b = self.bottleneck(self.pool(e3))\n",
    "\n",
    "        # --- ë””ì½”ë” + Skip Connections ---\n",
    "        d3 = self.upconv3(b)\n",
    "        d3 = torch.cat([d3, e3], dim=1)\n",
    "        d3 = self.dec3(d3)\n",
    "\n",
    "        d2 = self.upconv2(d3)\n",
    "        d2 = torch.cat([d2, e2], dim=1)\n",
    "        d2 = self.dec2(d2)\n",
    "\n",
    "        d1 = self.upconv1(d2)\n",
    "        d1 = torch.cat([d1, e1], dim=1)\n",
    "        d1 = self.dec1(d1)\n",
    "\n",
    "        # --- ì¶œë ¥ ---\n",
    "        out = self.out_conv(d1)\n",
    "        return out.squeeze(1) # (B, N, N)\n",
    "\n",
    "# --- í—¬í¼ í•¨ìˆ˜ ì •ì˜ (ì´ì „ê³¼ ë™ì¼) ---\n",
    "def save_phase_as_image(phase_tensor, filename):\n",
    "    phase_normalized = (phase_tensor.detach() + torch.pi) / (2 * torch.pi)\n",
    "    phase_uint8 = (phase_normalized * 255).byte().cpu().numpy()\n",
    "    Image.fromarray(phase_uint8).save(filename)\n",
    "\n",
    "def load_and_preprocess_image(path, size=(N, N)):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None: raise FileNotFoundError(f\"'{path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    img = cv2.resize(img, dsize=size)\n",
    "    img_float = img.astype(np.float32) / np.max(img) # 0~1 ì‚¬ì´ë¡œ ì •ê·œí™”\n",
    "    return torch.from_numpy(img_float).to('cpu')\n",
    "\n",
    "def fresnel_cuda(image, lam, dx, z):\n",
    "    N = 600\n",
    "    L = N * dx\n",
    "\n",
    "    x = torch.linspace(-L/2, L/2, N).cuda()\n",
    "    y = x\n",
    "    X, Y = torch.meshgrid(x, y)\n",
    "\n",
    "    k = 2 * torch.pi / lam\n",
    "    k = k.cuda()\n",
    "\n",
    "    coeff = torch.exp(1j * k * z) / (1j * lam * z)\n",
    "    kernel = coeff * torch.exp(1j * k / 2 / z * (X**2 + Y**2))\n",
    "    transfer = torch.fft.fftshift(torch.fft.fft2(kernel))\n",
    "\n",
    "    f_image = torch.fft.fftshift(torch.fft.fft2(image))\n",
    "    f_image = f_image * transfer\n",
    "    image = torch.fft.ifft2(torch.fft.ifftshift(f_image))\n",
    "    image = torch.fft.fftshift(image) # Don't know why do this but this should be exist\n",
    "    return image\n",
    "\n",
    "# --- ğŸŒŸ ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜ ğŸŒŸ ---\n",
    "class HolographyDataset(Dataset):\n",
    "    def __init__(self, image_dir):\n",
    "        # ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°\n",
    "        self.image_paths = glob.glob(os.path.join(image_dir, '*.jpg')) + \\\n",
    "                           glob.glob(os.path.join(image_dir, '*.png'))\n",
    "                           \n",
    "        lam = 0.532e-6\n",
    "        dx = 12.5e-6\n",
    "        z = 100e-3\n",
    "\n",
    "        lam = torch.tensor(lam).cuda()\n",
    "        dx = torch.tensor(dx).cuda()\n",
    "        z = torch.tensor(z).cuda()\n",
    "\n",
    "        # ê° ì´ë¯¸ì§€ì— ëŒ€í•œ ìœ„ìƒ í…ì„œë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬\n",
    "        self.phase_tensors = {}\n",
    "        for path in self.image_paths:\n",
    "            # ì´ˆê¸° ìœ„ìƒì€ ëœë¤ìœ¼ë¡œ ìƒì„±\n",
    "            target_intensity = load_and_preprocess_image(path)\n",
    "            target_amplitude = torch.sqrt(target_intensity).cuda()\n",
    "            field = fresnel_cuda(target_amplitude, lam, dx, -z)\n",
    "            phase = torch.angle(field).requires_grad_(True)\n",
    "            self.phase_tensors[path] = phase\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = self.image_paths[idx]\n",
    "        target_intensity = load_and_preprocess_image(path)\n",
    "        target_amplitude = torch.sqrt(target_intensity)\n",
    "        phase_tensor = self.phase_tensors[path]\n",
    "        return target_amplitude.to('cuda'), phase_tensor.to('cuda'), path # ê²½ë¡œë„ í•¨ê»˜ ë°˜í™˜í•˜ì—¬ ì¶”ì \n",
    "\n",
    "# --- ë³€ìˆ˜ ë° ëª¨ë¸ ì´ˆê¸°í™” ---\n",
    "model = MediumUNetPropagation().to(device)\n",
    "\n",
    "# ğŸŒŸ ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ìƒì„±\n",
    "# 'images' í´ë”ì— í•™ìŠµìš© ì´ë¯¸ì§€ë¥¼ ë„£ì–´ì£¼ì„¸ìš”.\n",
    "dataset = HolographyDataset(image_dir='./images')\n",
    "# ë¯¸ë‹ˆë°°ì¹˜ í¬ê¸°. GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì ˆ.\n",
    "BATCH_SIZE = 1\n",
    "data_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# s1, s2 ìŠ¤ì¼€ì¼ íŒ©í„°. ì´ì œ ì´ë¯¸ì§€ë§ˆë‹¤ í•„ìš”í•  ìˆ˜ ìˆìœ¼ë‚˜, ìš°ì„ ì€ ê³µìœ \n",
    "s1 = torch.tensor(1.0, device=device, requires_grad=True)\n",
    "s2 = torch.tensor(1.0, device=device, requires_grad=True)\n",
    "\n",
    "# â€¼ï¸ ì˜µí‹°ë§ˆì´ì € ì •ì˜. ì´ì œ ìœ„ìƒ í…ì„œëŠ” ë°ì´í„°ì…‹ ì•ˆì— ìˆìœ¼ë¯€ë¡œ, ë³„ë„ë¡œ ìµœì í™”\n",
    "optimizer_model = optim.Adam(list(model.parameters()) + [s2], lr=LEARNING_RATE_MODEL)\n",
    "# ìœ„ìƒ í…ì„œë“¤ì„ ëª¨ì•„ì„œ phase ì˜µí‹°ë§ˆì´ì €ì— ë“±ë¡\n",
    "all_phase_params = list(dataset.phase_tensors.values()) + [s1]\n",
    "optimizer_phase = optim.Adam(all_phase_params, lr=LEARNING_RATE_PHASE)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "print(f\"\\n--- ì´ˆê¸°í™” ì™„ë£Œ ---\")\n",
    "print(f\"\\n--- ì´ˆê¸°í™” ì™„ë£Œ ---\")\n",
    "print(f\"ì´ {len(dataset)}ê°œì˜ ì´ë¯¸ì§€ë¡œ ë°ì´í„°ì…‹ êµ¬ì„± ì™„ë£Œ.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298bb775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â€¼ï¸ ì˜µí‹°ë§ˆì´ì € ì •ì˜. ì´ì œ ìœ„ìƒ í…ì„œëŠ” ë°ì´í„°ì…‹ ì•ˆì— ìˆìœ¼ë¯€ë¡œ, ë³„ë„ë¡œ ìµœì í™”\n",
    "optimizer_model = optim.Adam(list(model.parameters()) + [s2], lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08ecedfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Epoch 1/15 ====================\n",
      "Epoch 1, Batch 1 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.022373\n",
      "Epoch 1, Batch 1 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 1, Batch 2 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.065856\n",
      "Epoch 1, Batch 2 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 1, Batch 3 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.056265\n",
      "Epoch 1, Batch 3 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 1, Batch 4 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.132284\n",
      "Epoch 1, Batch 4 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 1, Batch 5 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.089095\n",
      "Epoch 1, Batch 5 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 1, Batch 6 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.038387\n",
      "Epoch 1, Batch 6 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 1, Batch 7 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.034121\n",
      "Epoch 1, Batch 7 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "\n",
      "==================== Epoch 2/15 ====================\n",
      "Epoch 2, Batch 1 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.019435\n",
      "Epoch 2, Batch 1 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 2, Batch 2 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.065524\n",
      "Epoch 2, Batch 2 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 2, Batch 3 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.032131\n",
      "Epoch 2, Batch 3 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 2, Batch 4 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.058664\n",
      "Epoch 2, Batch 4 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 2, Batch 5 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.055240\n",
      "Epoch 2, Batch 5 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 2, Batch 6 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.027724\n",
      "Epoch 2, Batch 6 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 2, Batch 7 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.046988\n",
      "Epoch 2, Batch 7 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "\n",
      "==================== Epoch 3/15 ====================\n",
      "Epoch 3, Batch 1 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.045398\n",
      "Epoch 3, Batch 1 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 3, Batch 2 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.083459\n",
      "Epoch 3, Batch 2 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 3, Batch 3 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.044907\n",
      "Epoch 3, Batch 3 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 3, Batch 4 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.035890\n",
      "Epoch 3, Batch 4 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 3, Batch 5 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.062454\n",
      "Epoch 3, Batch 5 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 3, Batch 6 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.085972\n",
      "Epoch 3, Batch 6 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 3, Batch 7 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.125628\n",
      "Epoch 3, Batch 7 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "\n",
      "==================== Epoch 4/15 ====================\n",
      "Epoch 4, Batch 1 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.032503\n",
      "Epoch 4, Batch 1 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 4, Batch 2 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.108616\n",
      "Epoch 4, Batch 2 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 4, Batch 3 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.094939\n",
      "Epoch 4, Batch 3 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 4, Batch 4 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.135647\n",
      "Epoch 4, Batch 4 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 4, Batch 5 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.095661\n",
      "Epoch 4, Batch 5 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 4, Batch 6 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.048363\n",
      "Epoch 4, Batch 6 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 4, Batch 7 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.150413\n",
      "Epoch 4, Batch 7 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "\n",
      "==================== Epoch 5/15 ====================\n",
      "Epoch 5, Batch 1 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.115471\n",
      "Epoch 5, Batch 1 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 5, Batch 2 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.075649\n",
      "Epoch 5, Batch 2 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 5, Batch 3 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.093131\n",
      "Epoch 5, Batch 3 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 5, Batch 4 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.133600\n",
      "Epoch 5, Batch 4 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 5, Batch 5 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.033066\n",
      "Epoch 5, Batch 5 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 5, Batch 6 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.044808\n",
      "Epoch 5, Batch 6 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 5, Batch 7 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.118147\n",
      "Epoch 5, Batch 7 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "\n",
      "==================== Epoch 6/15 ====================\n",
      "Epoch 6, Batch 1 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.033464\n",
      "Epoch 6, Batch 1 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 6, Batch 2 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.070910\n",
      "Epoch 6, Batch 2 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 6, Batch 3 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.106536\n",
      "Epoch 6, Batch 3 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 6, Batch 4 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.086083\n",
      "Epoch 6, Batch 4 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 6, Batch 5 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.111469\n",
      "Epoch 6, Batch 5 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 6, Batch 6 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.062918\n",
      "Epoch 6, Batch 6 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 6, Batch 7 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.041588\n",
      "Epoch 6, Batch 7 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "\n",
      "==================== Epoch 7/15 ====================\n",
      "Epoch 7, Batch 1 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.032487\n",
      "Epoch 7, Batch 1 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 7, Batch 2 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.043591\n",
      "Epoch 7, Batch 2 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 7, Batch 3 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.068316\n",
      "Epoch 7, Batch 3 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 7, Batch 4 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.109601\n",
      "Epoch 7, Batch 4 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 7, Batch 5 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.064238\n",
      "Epoch 7, Batch 5 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 7, Batch 6 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.064028\n",
      "Epoch 7, Batch 6 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 7, Batch 7 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.106791\n",
      "Epoch 7, Batch 7 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "\n",
      "==================== Epoch 8/15 ====================\n",
      "Epoch 8, Batch 1 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.060581\n",
      "Epoch 8, Batch 1 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 8, Batch 2 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.053138\n",
      "Epoch 8, Batch 2 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 8, Batch 3 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.108632\n",
      "Epoch 8, Batch 3 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 8, Batch 4 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.038877\n",
      "Epoch 8, Batch 4 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 8, Batch 5 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.095221\n",
      "Epoch 8, Batch 5 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 8, Batch 6 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.071071\n",
      "Epoch 8, Batch 6 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 8, Batch 7 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.038562\n",
      "Epoch 8, Batch 7 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "\n",
      "==================== Epoch 9/15 ====================\n",
      "Epoch 9, Batch 1 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.047880\n",
      "Epoch 9, Batch 1 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 9, Batch 2 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.039079\n",
      "Epoch 9, Batch 2 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 9, Batch 3 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.107223\n",
      "Epoch 9, Batch 3 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 9, Batch 4 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.061533\n",
      "Epoch 9, Batch 4 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 9, Batch 5 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.068095\n",
      "Epoch 9, Batch 5 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 9, Batch 6 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.035450\n",
      "Epoch 9, Batch 6 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 9, Batch 7 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.096409\n",
      "Epoch 9, Batch 7 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "\n",
      "==================== Epoch 10/15 ====================\n",
      "Epoch 10, Batch 1 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.062785\n",
      "Epoch 10, Batch 1 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 10, Batch 2 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.067094\n",
      "Epoch 10, Batch 2 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 10, Batch 3 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.032994\n",
      "Epoch 10, Batch 3 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 10, Batch 4 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.095104\n",
      "Epoch 10, Batch 4 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 10, Batch 5 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.090300\n",
      "Epoch 10, Batch 5 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 10, Batch 6 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.044740\n",
      "Epoch 10, Batch 6 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 10, Batch 7 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.035774\n",
      "Epoch 10, Batch 7 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "\n",
      "==================== Epoch 11/15 ====================\n",
      "Epoch 11, Batch 1 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.032212\n",
      "Epoch 11, Batch 1 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 11, Batch 2 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.033913\n",
      "Epoch 11, Batch 2 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 11, Batch 3 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.092810\n",
      "Epoch 11, Batch 3 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 11, Batch 4 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.085376\n",
      "Epoch 11, Batch 4 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 11, Batch 5 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.064328\n",
      "Epoch 11, Batch 5 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 11, Batch 6 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.062619\n",
      "Epoch 11, Batch 6 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 11, Batch 7 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.040872\n",
      "Epoch 11, Batch 7 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "\n",
      "==================== Epoch 12/15 ====================\n",
      "Epoch 12, Batch 1 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.091143\n",
      "Epoch 12, Batch 1 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 12, Batch 2 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.071950\n",
      "Epoch 12, Batch 2 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 12, Batch 3 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.037524\n",
      "Epoch 12, Batch 3 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 12, Batch 4 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.032357\n",
      "Epoch 12, Batch 4 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 12, Batch 5 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.083861\n",
      "Epoch 12, Batch 5 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 12, Batch 6 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.064674\n",
      "Epoch 12, Batch 6 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 12, Batch 7 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.038995\n",
      "Epoch 12, Batch 7 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "\n",
      "==================== Epoch 13/15 ====================\n",
      "Epoch 13, Batch 1 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.035872\n",
      "Epoch 13, Batch 1 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 13, Batch 2 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.074475\n",
      "Epoch 13, Batch 2 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 13, Batch 3 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.039508\n",
      "Epoch 13, Batch 3 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 13, Batch 4 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.062479\n",
      "Epoch 13, Batch 4 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 13, Batch 5 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.095753\n",
      "Epoch 13, Batch 5 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 13, Batch 6 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.035079\n",
      "Epoch 13, Batch 6 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 13, Batch 7 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.096380\n",
      "Epoch 13, Batch 7 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "\n",
      "==================== Epoch 14/15 ====================\n",
      "Epoch 14, Batch 1 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.097383\n",
      "Epoch 14, Batch 1 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 14, Batch 2 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.034780\n",
      "Epoch 14, Batch 2 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 14, Batch 3 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.081735\n",
      "Epoch 14, Batch 3 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 14, Batch 4 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.109297\n",
      "Epoch 14, Batch 4 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 14, Batch 5 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.057384\n",
      "Epoch 14, Batch 5 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 14, Batch 6 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.148094\n",
      "Epoch 14, Batch 6 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 14, Batch 7 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.037313\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 48\u001b[39m\n\u001b[32m     45\u001b[39m save_phase_as_image(phase_to_display, \u001b[33m'\u001b[39m\u001b[33mtest.png\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     47\u001b[39m slm_process = subprocess.Popen([\u001b[33m'\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtest.py\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# â€¼ï¸ ì‹¤ì œ ì¹´ë©”ë¼ ì´¬ì˜ ë¡œì§\u001b[39;00m\n\u001b[32m     51\u001b[39m camera = Lucam()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from pytorch_msssim import ssim, ms_ssim # Multi-Scale SSIMì´ ë” ì„±ëŠ¥ì´ ì¢‹ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "import torch.nn.functional as F\n",
    "\n",
    "NUM_EPOCHS = 15 # ì „ì²´ ë°ì´í„°ì…‹ì„ ëª‡ ë²ˆ ë°˜ë³µí• ì§€\n",
    "lam = 0.532e-6\n",
    "dx = 12.5e-6\n",
    "z = 100e-3\n",
    "\n",
    "lam = torch.tensor(lam).cuda()\n",
    "dx = torch.tensor(dx).cuda()\n",
    "z = torch.tensor(z).cuda()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\n{'='*20} Epoch {epoch + 1}/{NUM_EPOCHS} {'='*20}\")\n",
    "    \n",
    "        # data_loaderì—ì„œ ë¯¸ë‹ˆë°°ì¹˜ ë‹¨ìœ„ë¡œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜´\n",
    "    for i, (target_amplitudes, phase_tensors, image_paths) in enumerate(data_loader):\n",
    "        \n",
    "        # --- ë‹¨ê³„ 1: ìœ„ìƒ ì—…ë°ì´íŠ¸ -\n",
    "        model.eval()\n",
    "        optimizer_phase.zero_grad()\n",
    "        \n",
    "        # U-Net ëª¨ë¸ì€ ë°°ì¹˜ ì…ë ¥ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ ìˆ˜ì •ë¨\n",
    "        prediction_for_phase = model(phase_tensors)\n",
    "\n",
    "        field = torch.exp(1j * prediction_for_phase)\n",
    "        propagated_field = fresnel_cuda(field, lam, dx, z)\n",
    "        prediction_for_phase = torch.abs(propagated_field)\n",
    "        prediction_for_phase = prediction_for_phase/torch.max(prediction_for_phase).item()\n",
    "\n",
    "        loss_phase = loss_fn(s1 * prediction_for_phase, target_amplitudes)\n",
    "        loss_phase.backward()\n",
    "        optimizer_phase.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}, Batch {i+1} [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: {loss_phase.item():.6f}\")\n",
    "\n",
    "        # --- ë‹¨ê³„ 2: ëª¨ë¸ ì—…ë°ì´íŠ¸ ---\n",
    "        # ì´ ë‹¨ê³„ì—ì„œëŠ” ë¯¸ë‹ˆë°°ì¹˜ì˜ ê° ì´ë¯¸ì§€ì— ëŒ€í•´ ë¬¼ë¦¬ì  ì‹¤í—˜ì„ ë°˜ë³µí•´ì•¼ í•¨\n",
    "        \n",
    "        captured_amplitudes_batch = []\n",
    "        # ë°°ì¹˜ ë‚´ ê° ìƒ˜í”Œì— ëŒ€í•´ SLM ë„ìš°ê³  ì´¬ì˜\n",
    "        for j in range(len(image_paths)):\n",
    "            phase_to_display = phase_tensors[j]\n",
    "            \n",
    "            save_phase_as_image(phase_to_display, 'test.png')\n",
    "            \n",
    "            slm_process = subprocess.Popen(['python', 'test.py'])\n",
    "            time.sleep(2)\n",
    "            \n",
    "            # â€¼ï¸ ì‹¤ì œ ì¹´ë©”ë¼ ì´¬ì˜ ë¡œì§\n",
    "            camera = Lucam()\n",
    "            capture = camera.TakeSnapshot()\n",
    "            capture = cv2.resize(capture, dsize=(N, N))\n",
    "            cv2.imwrite('captured_image.png', capture)\n",
    "            \n",
    "            slm_process.terminate()\n",
    "            slm_process.wait()\n",
    "\n",
    "            captured_amp = torch.sqrt(load_and_preprocess_image('captured_image.png'))\n",
    "            captured_amplitudes_batch.append(captured_amp)\n",
    "        \n",
    "        # ì´¬ì˜ëœ ì´ë¯¸ì§€ë“¤ì„ í•˜ë‚˜ì˜ ë°°ì¹˜ í…ì„œë¡œ ê²°í•©\n",
    "        captured_amplitudes = torch.stack(captured_amplitudes_batch)\n",
    "        \n",
    "        # ëª¨ë¸ í•™ìŠµ\n",
    "        model.train()\n",
    "        optimizer_model.zero_grad()\n",
    "        \n",
    "        # phase_tensorsëŠ” ì—…ë°ì´íŠ¸ë˜ì—ˆì§€ë§Œ, ëª¨ë¸ í•™ìŠµì—ëŠ” ì´ì „ ìƒíƒœë¥¼ ì‚¬ìš©í•´ì•¼ í•¨\n",
    "        prediction_for_model = model(phase_tensors.detach())\n",
    "\n",
    "        field = torch.exp(1j * prediction_for_model)\n",
    "        propagated_field = fresnel_cuda(field, lam, dx, z)\n",
    "        prediction_for_model = torch.abs(propagated_field)\n",
    "        prediction_for_model = prediction_for_model / torch.max(prediction_for_model).item()\n",
    "\n",
    "        loss_model = loss_fn(s2 * prediction_for_model, captured_amplitudes.cuda())\n",
    "        loss_model.backward()\n",
    "        optimizer_model.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}, Batch {i+1} [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\")\n",
    "        temp = phase_tensors.clone()\n",
    "        output = model(temp.detach()).detach().cpu().numpy()[0]\n",
    "        output = (output - np.min(output)) / (np.max(output) - np.min(output))\n",
    "        output = output * 255\n",
    "        Image.fromarray(output.astype('uint8')).save('output.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "holo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
