{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d514908",
   "metadata": {},
   "source": [
    "<h1> Neural Net </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97e40d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "--- ì´ˆê¸°í™” ì™„ë£Œ ---\n",
      "\n",
      "--- ì´ˆê¸°í™” ì™„ë£Œ ---\n",
      "ì´ 8ê°œì˜ ì´ë¯¸ì§€ë¡œ ë°ì´í„°ì…‹ êµ¬ì„± ì™„ë£Œ.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from lucam import Lucam\n",
    "\n",
    "# --- ê¸°ë³¸ ì„¤ì • (ì´ì „ê³¼ ë™ì¼) ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "N = 600\n",
    "LEARNING_RATE_MODEL = 1e-3\n",
    "LEARNING_RATE_PHASE = 1e-3\n",
    "\n",
    "# --- ğŸ§  ì¤‘ê°„ ê¹Šì´ì˜ ë‰´ëŸ´ ë„¤íŠ¸ì›Œí¬ ëª¨ë¸ ì •ì˜ ---\n",
    "class MediumUNetPropagation(nn.Module):\n",
    "    def __init__(self, in_channels=2, out_channels=1):\n",
    "        super(MediumUNetPropagation, self).__init__()\n",
    "\n",
    "        # --- ì¸ì½”ë” (Contracting Path) ---\n",
    "        # Level 1\n",
    "        self.enc1 = self.conv_block(in_channels, 64)\n",
    "        # Level 2\n",
    "        self.enc2 = self.conv_block(64, 128)\n",
    "        # Level 3 (ì¶”ê°€ëœ ê¹Šì´)\n",
    "        self.enc3 = self.conv_block(128, 256)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # --- ë³‘ëª© êµ¬ê°„ (Bottleneck) ---\n",
    "        self.bottleneck = self.conv_block(256, 512)\n",
    "\n",
    "        # --- ë””ì½”ë” (Expanding Path) ---\n",
    "        # Level 3\n",
    "        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec3 = self.conv_block(256 + 256, 256) # Skip connection í¬í•¨\n",
    "        # Level 2\n",
    "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec2 = self.conv_block(128 + 128, 128) # Skip connection í¬í•¨\n",
    "        # Level 1\n",
    "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec1 = self.conv_block(64 + 64, 64)   # Skip connection í¬í•¨\n",
    "\n",
    "        # --- ìµœì¢… ì¶œë ¥ ë ˆì´ì–´ ---\n",
    "        self.out_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def conv_block(self, in_c, out_c):\n",
    "        \"\"\"ë‘ ê°œì˜ 3x3 Convì™€ ReLU, BatchNormìœ¼ë¡œ êµ¬ì„±ëœ ê¸°ë³¸ ë¸”ë¡\"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_c, out_c, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, phase_map):\n",
    "        # â€¼ï¸ ì…ë ¥ ë³€í™˜: Ï† -> [cos(Ï†), sin(Ï†)]\n",
    "        if phase_map.dim() == 3: # (B, H, W) -> (B, 1, H, W)\n",
    "            phase_map = phase_map.unsqueeze(1)\n",
    "\n",
    "        x_cos = torch.cos(phase_map)\n",
    "        x_sin = torch.sin(phase_map)\n",
    "        x = torch.cat([x_cos, x_sin], dim=1) # (B, 2, N, N)\n",
    "\n",
    "        # --- ì¸ì½”ë” ---\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool(e1))\n",
    "        e3 = self.enc3(self.pool(e2))\n",
    "\n",
    "        # --- ë³‘ëª© ---\n",
    "        b = self.bottleneck(self.pool(e3))\n",
    "\n",
    "        # --- ë””ì½”ë” + Skip Connections ---\n",
    "        d3 = self.upconv3(b)\n",
    "        d3 = torch.cat([d3, e3], dim=1)\n",
    "        d3 = self.dec3(d3)\n",
    "\n",
    "        d2 = self.upconv2(d3)\n",
    "        d2 = torch.cat([d2, e2], dim=1)\n",
    "        d2 = self.dec2(d2)\n",
    "\n",
    "        d1 = self.upconv1(d2)\n",
    "        d1 = torch.cat([d1, e1], dim=1)\n",
    "        d1 = self.dec1(d1)\n",
    "\n",
    "        # --- ì¶œë ¥ ---\n",
    "        out = self.out_conv(d1)\n",
    "        return out.squeeze(1) # (B, N, N)\n",
    "\n",
    "# --- í—¬í¼ í•¨ìˆ˜ ì •ì˜ (ì´ì „ê³¼ ë™ì¼) ---\n",
    "def save_phase_as_image(phase_tensor, filename):\n",
    "    phase_normalized = (phase_tensor.detach() + torch.pi) / (2 * torch.pi)\n",
    "    phase_uint8 = (phase_normalized * 255).byte().cpu().numpy()\n",
    "    Image.fromarray(phase_uint8).save(filename)\n",
    "\n",
    "def load_and_preprocess_image(path, size=(N, N)):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None: raise FileNotFoundError(f\"'{path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    img = cv2.resize(img, dsize=size)\n",
    "    img_float = img.astype(np.float32) / np.max(img) # 0~1 ì‚¬ì´ë¡œ ì •ê·œí™”\n",
    "    return torch.from_numpy(img_float).to('cpu')\n",
    "\n",
    "def fresnel_cuda(image, lam, dx, z):\n",
    "    N = 600\n",
    "    L = N * dx\n",
    "\n",
    "    x = torch.linspace(-L/2, L/2, N).cuda()\n",
    "    y = x\n",
    "    X, Y = torch.meshgrid(x, y)\n",
    "\n",
    "    k = 2 * torch.pi / lam\n",
    "    k = k.cuda()\n",
    "\n",
    "    coeff = torch.exp(1j * k * z) / (1j * lam * z)\n",
    "    kernel = coeff * torch.exp(1j * k / 2 / z * (X**2 + Y**2))\n",
    "    transfer = torch.fft.fftshift(torch.fft.fft2(kernel))\n",
    "\n",
    "    f_image = torch.fft.fftshift(torch.fft.fft2(image))\n",
    "    f_image = f_image * transfer\n",
    "    image = torch.fft.ifft2(torch.fft.ifftshift(f_image))\n",
    "    image = torch.fft.fftshift(image) # Don't know why do this but this should be exist\n",
    "    return image\n",
    "\n",
    "# --- ğŸŒŸ ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜ ğŸŒŸ ---\n",
    "class HolographyDataset(Dataset):\n",
    "    def __init__(self, image_dir):\n",
    "        # ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°\n",
    "        self.image_paths = glob.glob(os.path.join(image_dir, '*.jpg')) + \\\n",
    "                           glob.glob(os.path.join(image_dir, '*.png'))\n",
    "                           \n",
    "        lam = 0.532e-6\n",
    "        dx = 12.5e-6\n",
    "        z = 100e-3\n",
    "\n",
    "        lam = torch.tensor(lam).cuda()\n",
    "        dx = torch.tensor(dx).cuda()\n",
    "        z = torch.tensor(z).cuda()\n",
    "\n",
    "        # ê° ì´ë¯¸ì§€ì— ëŒ€í•œ ìœ„ìƒ í…ì„œë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬\n",
    "        self.phase_tensors = {}\n",
    "        for path in self.image_paths:\n",
    "            # ì´ˆê¸° ìœ„ìƒì€ ëœë¤ìœ¼ë¡œ ìƒì„±\n",
    "            target_intensity = load_and_preprocess_image(path)\n",
    "            target_amplitude = torch.sqrt(target_intensity).cuda()\n",
    "            field = fresnel_cuda(target_amplitude, lam, dx, -z)\n",
    "            phase = torch.angle(field).requires_grad_(True)\n",
    "            self.phase_tensors[path] = phase\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = self.image_paths[idx]\n",
    "        target_intensity = load_and_preprocess_image(path)\n",
    "        target_amplitude = torch.sqrt(target_intensity)\n",
    "        phase_tensor = self.phase_tensors[path]\n",
    "        return target_amplitude.to('cuda'), phase_tensor.to('cuda'), path # ê²½ë¡œë„ í•¨ê»˜ ë°˜í™˜í•˜ì—¬ ì¶”ì \n",
    "\n",
    "# --- ë³€ìˆ˜ ë° ëª¨ë¸ ì´ˆê¸°í™” ---\n",
    "model = MediumUNetPropagation().to(device)\n",
    "\n",
    "# ğŸŒŸ ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ìƒì„±\n",
    "# 'images' í´ë”ì— í•™ìŠµìš© ì´ë¯¸ì§€ë¥¼ ë„£ì–´ì£¼ì„¸ìš”.\n",
    "dataset = HolographyDataset(image_dir='./images')\n",
    "# ë¯¸ë‹ˆë°°ì¹˜ í¬ê¸°. GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì ˆ.\n",
    "BATCH_SIZE = 1\n",
    "data_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# s1, s2 ìŠ¤ì¼€ì¼ íŒ©í„°. ì´ì œ ì´ë¯¸ì§€ë§ˆë‹¤ í•„ìš”í•  ìˆ˜ ìˆìœ¼ë‚˜, ìš°ì„ ì€ ê³µìœ \n",
    "s1 = torch.tensor(1.0, device=device, requires_grad=True)\n",
    "s2 = torch.tensor(1.0, device=device, requires_grad=True)\n",
    "\n",
    "# â€¼ï¸ ì˜µí‹°ë§ˆì´ì € ì •ì˜. ì´ì œ ìœ„ìƒ í…ì„œëŠ” ë°ì´í„°ì…‹ ì•ˆì— ìˆìœ¼ë¯€ë¡œ, ë³„ë„ë¡œ ìµœì í™”\n",
    "optimizer_model = optim.Adam(list(model.parameters()) + [s2], lr=LEARNING_RATE_MODEL)\n",
    "# ìœ„ìƒ í…ì„œë“¤ì„ ëª¨ì•„ì„œ phase ì˜µí‹°ë§ˆì´ì €ì— ë“±ë¡\n",
    "all_phase_params = list(dataset.phase_tensors.values()) + [s1]\n",
    "optimizer_phase = optim.Adam(all_phase_params, lr=LEARNING_RATE_PHASE)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "print(f\"\\n--- ì´ˆê¸°í™” ì™„ë£Œ ---\")\n",
    "print(f\"\\n--- ì´ˆê¸°í™” ì™„ë£Œ ---\")\n",
    "print(f\"ì´ {len(dataset)}ê°œì˜ ì´ë¯¸ì§€ë¡œ ë°ì´í„°ì…‹ êµ¬ì„± ì™„ë£Œ.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298bb775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â€¼ï¸ ì˜µí‹°ë§ˆì´ì € ì •ì˜. ì´ì œ ìœ„ìƒ í…ì„œëŠ” ë°ì´í„°ì…‹ ì•ˆì— ìˆìœ¼ë¯€ë¡œ, ë³„ë„ë¡œ ìµœì í™”\n",
    "optimizer_model = optim.Adam(list(model.parameters()) + [s2], lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08ecedfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Epoch 1/15 ====================\n",
      "Epoch 1, Batch 1 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.066171\n",
      "Epoch 1, Batch 1 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 1, Batch 2 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.138095\n",
      "Epoch 1, Batch 2 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 1, Batch 3 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.044803\n",
      "Epoch 1, Batch 3 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 1, Batch 4 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.017946\n",
      "Epoch 1, Batch 4 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 1, Batch 5 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.078836\n",
      "Epoch 1, Batch 5 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 1, Batch 6 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.019213\n",
      "Epoch 1, Batch 6 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 1, Batch 7 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.033089\n",
      "Epoch 1, Batch 7 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 1, Batch 8 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.049394\n",
      "Epoch 1, Batch 8 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "\n",
      "==================== Epoch 2/15 ====================\n",
      "Epoch 2, Batch 1 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.038773\n",
      "Epoch 2, Batch 1 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 2, Batch 2 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.371331\n",
      "Epoch 2, Batch 2 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 2, Batch 3 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.464088\n",
      "Epoch 2, Batch 3 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 2, Batch 4 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.511777\n",
      "Epoch 2, Batch 4 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 2, Batch 5 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.364322\n",
      "Epoch 2, Batch 5 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 2, Batch 6 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.233395\n",
      "Epoch 2, Batch 6 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 2, Batch 7 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.221907\n",
      "Epoch 2, Batch 7 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 2, Batch 8 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.064329\n",
      "Epoch 2, Batch 8 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "\n",
      "==================== Epoch 3/15 ====================\n",
      "Epoch 3, Batch 1 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.171499\n",
      "Epoch 3, Batch 1 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 3, Batch 2 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.047819\n",
      "Epoch 3, Batch 2 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 3, Batch 3 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.196815\n",
      "Epoch 3, Batch 3 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 3, Batch 4 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.031278\n",
      "Epoch 3, Batch 4 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 3, Batch 5 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.035209\n",
      "Epoch 3, Batch 5 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 3, Batch 6 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.037680\n",
      "Epoch 3, Batch 6 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 3, Batch 7 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.076898\n",
      "Epoch 3, Batch 7 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 3, Batch 8 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.074889\n",
      "Epoch 3, Batch 8 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "\n",
      "==================== Epoch 4/15 ====================\n",
      "Epoch 4, Batch 1 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.032447\n",
      "Epoch 4, Batch 1 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 4, Batch 2 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.054283\n",
      "Epoch 4, Batch 2 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 4, Batch 3 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.074547\n",
      "Epoch 4, Batch 3 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 4, Batch 4 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.040436\n",
      "Epoch 4, Batch 4 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 4, Batch 5 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.036976\n",
      "Epoch 4, Batch 5 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 4, Batch 6 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.024752\n",
      "Epoch 4, Batch 6 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 4, Batch 7 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.040763\n",
      "Epoch 4, Batch 7 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 4, Batch 8 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.224237\n",
      "Epoch 4, Batch 8 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "\n",
      "==================== Epoch 5/15 ====================\n",
      "Epoch 5, Batch 1 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.076464\n",
      "Epoch 5, Batch 1 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 5, Batch 2 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.186034\n",
      "Epoch 5, Batch 2 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 5, Batch 3 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.215727\n",
      "Epoch 5, Batch 3 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 5, Batch 4 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.061529\n",
      "Epoch 5, Batch 4 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n",
      "Epoch 5, Batch 5 [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: 0.039542\n",
      "Epoch 5, Batch 5 [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 83\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     82\u001b[39m temp = phase_tensors.clone()\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m output = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.numpy()[\u001b[32m0\u001b[39m]\n\u001b[32m     84\u001b[39m output = (output - np.min(output)) / (np.max(output) - np.min(output))\n\u001b[32m     85\u001b[39m output = output * \u001b[32m255\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from pytorch_msssim import ssim, ms_ssim # Multi-Scale SSIMì´ ë” ì„±ëŠ¥ì´ ì¢‹ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "import torch.nn.functional as F\n",
    "\n",
    "NUM_EPOCHS = 15 # ì „ì²´ ë°ì´í„°ì…‹ì„ ëª‡ ë²ˆ ë°˜ë³µí• ì§€\n",
    "lam = 0.532e-6\n",
    "dx = 12.5e-6\n",
    "z = 100e-3\n",
    "\n",
    "lam = torch.tensor(lam).cuda()\n",
    "dx = torch.tensor(dx).cuda()\n",
    "z = torch.tensor(z).cuda()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\n{'='*20} Epoch {epoch + 1}/{NUM_EPOCHS} {'='*20}\")\n",
    "    \n",
    "        # data_loaderì—ì„œ ë¯¸ë‹ˆë°°ì¹˜ ë‹¨ìœ„ë¡œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜´\n",
    "    for i, (target_amplitudes, phase_tensors, image_paths) in enumerate(data_loader):\n",
    "        \n",
    "        # --- ë‹¨ê³„ 1: ìœ„ìƒ ì—…ë°ì´íŠ¸ -\n",
    "        model.eval()\n",
    "        optimizer_phase.zero_grad()\n",
    "        \n",
    "        # U-Net ëª¨ë¸ì€ ë°°ì¹˜ ì…ë ¥ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ ìˆ˜ì •ë¨\n",
    "        prediction_for_phase = model(phase_tensors)\n",
    "\n",
    "        field = torch.exp(1j * prediction_for_phase)\n",
    "        propagated_field = fresnel_cuda(field, lam, dx, z)\n",
    "        prediction_for_phase = torch.abs(propagated_field)\n",
    "        prediction_for_phase = prediction_for_phase/torch.max(prediction_for_phase).item()\n",
    "\n",
    "        loss_phase = loss_fn(s1 * prediction_for_phase, target_amplitudes)\n",
    "        loss_phase.backward()\n",
    "        optimizer_phase.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}, Batch {i+1} [1/2] ìœ„ìƒ ì—…ë°ì´íŠ¸ ì™„ë£Œ. Loss: {loss_phase.item():.6f}\")\n",
    "\n",
    "        # --- ë‹¨ê³„ 2: ëª¨ë¸ ì—…ë°ì´íŠ¸ ---\n",
    "        # ì´ ë‹¨ê³„ì—ì„œëŠ” ë¯¸ë‹ˆë°°ì¹˜ì˜ ê° ì´ë¯¸ì§€ì— ëŒ€í•´ ë¬¼ë¦¬ì  ì‹¤í—˜ì„ ë°˜ë³µí•´ì•¼ í•¨\n",
    "        \n",
    "        captured_amplitudes_batch = []\n",
    "        # ë°°ì¹˜ ë‚´ ê° ìƒ˜í”Œì— ëŒ€í•´ SLM ë„ìš°ê³  ì´¬ì˜\n",
    "        for j in range(len(image_paths)):\n",
    "            phase_to_display = phase_tensors[j]\n",
    "            \n",
    "            save_phase_as_image(phase_to_display, 'test.png')\n",
    "            \n",
    "            slm_process = subprocess.Popen(['python', 'test.py'])\n",
    "            time.sleep(2)\n",
    "            \n",
    "            # â€¼ï¸ ì‹¤ì œ ì¹´ë©”ë¼ ì´¬ì˜ ë¡œì§\n",
    "            camera = Lucam()\n",
    "            capture = camera.TakeSnapshot()\n",
    "            capture = cv2.resize(capture, dsize=(N, N))\n",
    "            cv2.imwrite('captured_image.png', capture)\n",
    "            \n",
    "            slm_process.terminate()\n",
    "            slm_process.wait()\n",
    "\n",
    "            captured_amp = torch.sqrt(load_and_preprocess_image('captured_image.png'))\n",
    "            captured_amplitudes_batch.append(captured_amp)\n",
    "        \n",
    "        # ì´¬ì˜ëœ ì´ë¯¸ì§€ë“¤ì„ í•˜ë‚˜ì˜ ë°°ì¹˜ í…ì„œë¡œ ê²°í•©\n",
    "        captured_amplitudes = torch.stack(captured_amplitudes_batch)\n",
    "        \n",
    "        # ëª¨ë¸ í•™ìŠµ\n",
    "        model.train()\n",
    "        optimizer_model.zero_grad()\n",
    "        \n",
    "        # phase_tensorsëŠ” ì—…ë°ì´íŠ¸ë˜ì—ˆì§€ë§Œ, ëª¨ë¸ í•™ìŠµì—ëŠ” ì´ì „ ìƒíƒœë¥¼ ì‚¬ìš©í•´ì•¼ í•¨\n",
    "        prediction_for_model = model(phase_tensors.detach())\n",
    "\n",
    "        field = torch.exp(1j * prediction_for_model)\n",
    "        propagated_field = fresnel_cuda(field, lam, dx, z)\n",
    "        prediction_for_model = torch.abs(propagated_field)\n",
    "        prediction_for_model = prediction_for_model / torch.max(prediction_for_model).item()\n",
    "\n",
    "        loss_model = loss_fn(s2 * prediction_for_model, captured_amplitudes.cuda())\n",
    "        loss_model.backward()\n",
    "        optimizer_model.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}, Batch {i+1} [2/2] ëª¨ë¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ.\")\n",
    "        temp = phase_tensors.clone()\n",
    "        output = model(temp.detach()).detach().cpu().numpy()[0]\n",
    "        output = (output - np.min(output)) / (np.max(output) - np.min(output))\n",
    "        output = output * 255\n",
    "        Image.fromarray(output.astype('uint8')).save('output.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9948be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9336, 0.3582, 0.7935, 0.0520, 0.3762, 0.8230, 0.8240, 0.7717, 0.0079,\n",
       "         0.2563],\n",
       "        [0.9462, 0.2194, 0.8983, 0.5424, 0.2604, 0.7501, 0.1395, 0.1190, 0.3600,\n",
       "         0.1297],\n",
       "        [0.3989, 0.1994, 0.9521, 0.5441, 0.9915, 0.8992, 0.0383, 0.1927, 0.6817,\n",
       "         0.8282],\n",
       "        [0.1613, 0.1447, 0.6904, 0.1973, 0.8128, 0.0421, 0.7949, 0.5161, 0.1538,\n",
       "         0.4465],\n",
       "        [0.2018, 0.4343, 0.7569, 0.5306, 0.7159, 0.2957, 0.6866, 0.0284, 0.2571,\n",
       "         0.9168],\n",
       "        [0.0722, 0.5894, 0.6778, 0.3464, 0.1135, 0.7081, 0.0522, 0.5975, 0.4147,\n",
       "         0.4051],\n",
       "        [0.4297, 0.0296, 0.8246, 0.1053, 0.2656, 0.4284, 0.0789, 0.7853, 0.7905,\n",
       "         0.3956],\n",
       "        [0.5438, 0.5039, 0.9148, 0.5283, 0.7852, 0.2799, 0.8295, 0.6605, 0.5125,\n",
       "         0.3032],\n",
       "        [0.1538, 0.1275, 0.0366, 0.4837, 0.3076, 0.3640, 0.7123, 0.4583, 0.7257,\n",
       "         0.0591],\n",
       "        [0.5978, 0.1666, 0.9902, 0.2688, 0.7349, 0.1601, 0.3599, 0.6982, 0.3267,\n",
       "         0.9377]], requires_grad=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand((10,10), requires_grad=True)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1317382a",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.max(torch.abs(a)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03fcbdf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cë¥¼ í†µí•´ ì—­ì „íŒŒ í›„ aì˜ ê·¸ë˜ë””ì–¸íŠ¸:\n",
      "tensor([[0.3333, 0.3333, 0.3333],\n",
      "        [0.3333, 0.3333, 0.3333]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# requires_grad=Trueë¡œ ì„¤ì •í•˜ì—¬ ê·¸ë˜ë””ì–¸íŠ¸ ì¶”ì \n",
    "a = torch.ones(2, 3, requires_grad=True)\n",
    "\n",
    "# 2. .item()ì„ ì‚¬ìš©í•œ ê²½ìš° (ê·¸ë˜ë””ì–¸íŠ¸ íë¦„ì´ ëŠê¹€)\n",
    "b = torch.max(torch.abs(a)).item()\n",
    "\n",
    "c = torch.max(torch.abs(a))\n",
    "loss = c * 2\n",
    "\n",
    "# ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ì˜ˆì‹œ\n",
    "# cëŠ” ì—°ì‚° ê·¸ë˜í”„ì— ì—°ê²°ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ì—­ì „íŒŒ ê°€ëŠ¥\n",
    "loss.backward()\n",
    "\n",
    "print(\"cë¥¼ í†µí•´ ì—­ì „íŒŒ í›„ aì˜ ê·¸ë˜ë””ì–¸íŠ¸:\")\n",
    "print(a.grad) # aì— ê·¸ë˜ë””ì–¸íŠ¸ê°€ ê³„ì‚°ë¨\n",
    "\n",
    "# bëŠ” íŒŒì´ì¬ ìˆ«ìì´ë¯€ë¡œ ì—­ì „íŒŒì˜ ì‹œì‘ì ì´ ë  ìˆ˜ ì—†ìŒ\n",
    "# ë§Œì•½ loss = b * 2 ë¼ê³  í•œ ë’¤ loss.backward()ë¥¼ ì‹œë„í•˜ë©´ ì—ëŸ¬ ë°œìƒ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "holo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
