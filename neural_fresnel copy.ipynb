{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d514908",
   "metadata": {},
   "source": [
    "<h1> Neural Net </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97e40d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "--- 초기화 완료 ---\n",
      "\n",
      "--- 초기화 완료 ---\n",
      "총 8개의 이미지로 데이터셋 구성 완료.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from lucam import Lucam\n",
    "\n",
    "# --- 기본 설정 (이전과 동일) ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "N = 600\n",
    "LEARNING_RATE_MODEL = 1e-3\n",
    "LEARNING_RATE_PHASE = 1e-3\n",
    "\n",
    "# --- 🧠 중간 깊이의 뉴럴 네트워크 모델 정의 ---\n",
    "class MediumUNetPropagation(nn.Module):\n",
    "    def __init__(self, in_channels=2, out_channels=1):\n",
    "        super(MediumUNetPropagation, self).__init__()\n",
    "\n",
    "        # --- 인코더 (Contracting Path) ---\n",
    "        # Level 1\n",
    "        self.enc1 = self.conv_block(in_channels, 64)\n",
    "        # Level 2\n",
    "        self.enc2 = self.conv_block(64, 128)\n",
    "        # Level 3 (추가된 깊이)\n",
    "        self.enc3 = self.conv_block(128, 256)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # --- 병목 구간 (Bottleneck) ---\n",
    "        self.bottleneck = self.conv_block(256, 512)\n",
    "\n",
    "        # --- 디코더 (Expanding Path) ---\n",
    "        # Level 3\n",
    "        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec3 = self.conv_block(256 + 256, 256) # Skip connection 포함\n",
    "        # Level 2\n",
    "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec2 = self.conv_block(128 + 128, 128) # Skip connection 포함\n",
    "        # Level 1\n",
    "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec1 = self.conv_block(64 + 64, 64)   # Skip connection 포함\n",
    "\n",
    "        # --- 최종 출력 레이어 ---\n",
    "        self.out_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def conv_block(self, in_c, out_c):\n",
    "        \"\"\"두 개의 3x3 Conv와 ReLU, BatchNorm으로 구성된 기본 블록\"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_c, out_c, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_c),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, phase_map):\n",
    "        # ‼️ 입력 변환: φ -> [cos(φ), sin(φ)]\n",
    "        if phase_map.dim() == 3: # (B, H, W) -> (B, 1, H, W)\n",
    "            phase_map = phase_map.unsqueeze(1)\n",
    "\n",
    "        x_cos = torch.cos(phase_map)\n",
    "        x_sin = torch.sin(phase_map)\n",
    "        x = torch.cat([x_cos, x_sin], dim=1) # (B, 2, N, N)\n",
    "\n",
    "        # --- 인코더 ---\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool(e1))\n",
    "        e3 = self.enc3(self.pool(e2))\n",
    "\n",
    "        # --- 병목 ---\n",
    "        b = self.bottleneck(self.pool(e3))\n",
    "\n",
    "        # --- 디코더 + Skip Connections ---\n",
    "        d3 = self.upconv3(b)\n",
    "        d3 = torch.cat([d3, e3], dim=1)\n",
    "        d3 = self.dec3(d3)\n",
    "\n",
    "        d2 = self.upconv2(d3)\n",
    "        d2 = torch.cat([d2, e2], dim=1)\n",
    "        d2 = self.dec2(d2)\n",
    "\n",
    "        d1 = self.upconv1(d2)\n",
    "        d1 = torch.cat([d1, e1], dim=1)\n",
    "        d1 = self.dec1(d1)\n",
    "\n",
    "        # --- 출력 ---\n",
    "        out = self.out_conv(d1)\n",
    "        return out.squeeze(1) # (B, N, N)\n",
    "\n",
    "# --- 헬퍼 함수 정의 (이전과 동일) ---\n",
    "def save_phase_as_image(phase_tensor, filename):\n",
    "    phase_normalized = (phase_tensor.detach() + torch.pi) / (2 * torch.pi)\n",
    "    phase_uint8 = (phase_normalized * 255).byte().cpu().numpy()\n",
    "    Image.fromarray(phase_uint8).save(filename)\n",
    "\n",
    "def load_and_preprocess_image(path, size=(N, N)):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None: raise FileNotFoundError(f\"'{path}' 파일을 찾을 수 없습니다.\")\n",
    "    img = cv2.resize(img, dsize=size)\n",
    "    img_float = img.astype(np.float32) / np.max(img) # 0~1 사이로 정규화\n",
    "    return torch.from_numpy(img_float).to('cpu')\n",
    "\n",
    "def fresnel_cuda(image, lam, dx, z):\n",
    "    N = 600\n",
    "    L = N * dx\n",
    "\n",
    "    x = torch.linspace(-L/2, L/2, N).cuda()\n",
    "    y = x\n",
    "    X, Y = torch.meshgrid(x, y)\n",
    "\n",
    "    k = 2 * torch.pi / lam\n",
    "    k = k.cuda()\n",
    "\n",
    "    coeff = torch.exp(1j * k * z) / (1j * lam * z)\n",
    "    kernel = coeff * torch.exp(1j * k / 2 / z * (X**2 + Y**2))\n",
    "    transfer = torch.fft.fftshift(torch.fft.fft2(kernel))\n",
    "\n",
    "    f_image = torch.fft.fftshift(torch.fft.fft2(image))\n",
    "    f_image = f_image * transfer\n",
    "    image = torch.fft.ifft2(torch.fft.ifftshift(f_image))\n",
    "    image = torch.fft.fftshift(image) # Don't know why do this but this should be exist\n",
    "    return image\n",
    "\n",
    "# --- 🌟 데이터셋 클래스 정의 🌟 ---\n",
    "class HolographyDataset(Dataset):\n",
    "    def __init__(self, image_dir):\n",
    "        # 이미지 파일 경로 리스트 가져오기\n",
    "        self.image_paths = glob.glob(os.path.join(image_dir, '*.jpg')) + \\\n",
    "                           glob.glob(os.path.join(image_dir, '*.png'))\n",
    "                           \n",
    "        lam = 0.532e-6\n",
    "        dx = 12.5e-6\n",
    "        z = 100e-3\n",
    "\n",
    "        lam = torch.tensor(lam).cuda()\n",
    "        dx = torch.tensor(dx).cuda()\n",
    "        z = torch.tensor(z).cuda()\n",
    "\n",
    "        # 각 이미지에 대한 위상 텐서를 저장할 딕셔너리\n",
    "        self.phase_tensors = {}\n",
    "        for path in self.image_paths:\n",
    "            # 초기 위상은 랜덤으로 생성\n",
    "            target_intensity = load_and_preprocess_image(path)\n",
    "            target_amplitude = torch.sqrt(target_intensity).cuda()\n",
    "            field = fresnel_cuda(target_amplitude, lam, dx, -z)\n",
    "            phase = torch.angle(field).requires_grad_(True)\n",
    "            self.phase_tensors[path] = phase\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = self.image_paths[idx]\n",
    "        target_intensity = load_and_preprocess_image(path)\n",
    "        target_amplitude = torch.sqrt(target_intensity)\n",
    "        phase_tensor = self.phase_tensors[path]\n",
    "        return target_amplitude.to('cuda'), phase_tensor.to('cuda'), path # 경로도 함께 반환하여 추적\n",
    "\n",
    "# --- 변수 및 모델 초기화 ---\n",
    "model = MediumUNetPropagation().to(device)\n",
    "\n",
    "# 🌟 데이터셋 및 데이터로더 생성\n",
    "# 'images' 폴더에 학습용 이미지를 넣어주세요.\n",
    "dataset = HolographyDataset(image_dir='./images')\n",
    "# 미니배치 크기. GPU 메모리에 따라 조절.\n",
    "BATCH_SIZE = 1\n",
    "data_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# s1, s2 스케일 팩터. 이제 이미지마다 필요할 수 있으나, 우선은 공유\n",
    "s1 = torch.tensor(1.0, device=device, requires_grad=True)\n",
    "s2 = torch.tensor(1.0, device=device, requires_grad=True)\n",
    "\n",
    "# ‼️ 옵티마이저 정의. 이제 위상 텐서는 데이터셋 안에 있으므로, 별도로 최적화\n",
    "optimizer_model = optim.Adam(list(model.parameters()) + [s2], lr=LEARNING_RATE_MODEL)\n",
    "# 위상 텐서들을 모아서 phase 옵티마이저에 등록\n",
    "all_phase_params = list(dataset.phase_tensors.values()) + [s1]\n",
    "optimizer_phase = optim.Adam(all_phase_params, lr=LEARNING_RATE_PHASE)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "print(f\"\\n--- 초기화 완료 ---\")\n",
    "print(f\"\\n--- 초기화 완료 ---\")\n",
    "print(f\"총 {len(dataset)}개의 이미지로 데이터셋 구성 완료.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298bb775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‼️ 옵티마이저 정의. 이제 위상 텐서는 데이터셋 안에 있으므로, 별도로 최적화\n",
    "optimizer_model = optim.Adam(list(model.parameters()) + [s2], lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08ecedfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Epoch 1/15 ====================\n",
      "Epoch 1, Batch 1 [1/2] 위상 업데이트 완료. Loss: 0.066171\n",
      "Epoch 1, Batch 1 [2/2] 모델 업데이트 완료.\n",
      "Epoch 1, Batch 2 [1/2] 위상 업데이트 완료. Loss: 0.138095\n",
      "Epoch 1, Batch 2 [2/2] 모델 업데이트 완료.\n",
      "Epoch 1, Batch 3 [1/2] 위상 업데이트 완료. Loss: 0.044803\n",
      "Epoch 1, Batch 3 [2/2] 모델 업데이트 완료.\n",
      "Epoch 1, Batch 4 [1/2] 위상 업데이트 완료. Loss: 0.017946\n",
      "Epoch 1, Batch 4 [2/2] 모델 업데이트 완료.\n",
      "Epoch 1, Batch 5 [1/2] 위상 업데이트 완료. Loss: 0.078836\n",
      "Epoch 1, Batch 5 [2/2] 모델 업데이트 완료.\n",
      "Epoch 1, Batch 6 [1/2] 위상 업데이트 완료. Loss: 0.019213\n",
      "Epoch 1, Batch 6 [2/2] 모델 업데이트 완료.\n",
      "Epoch 1, Batch 7 [1/2] 위상 업데이트 완료. Loss: 0.033089\n",
      "Epoch 1, Batch 7 [2/2] 모델 업데이트 완료.\n",
      "Epoch 1, Batch 8 [1/2] 위상 업데이트 완료. Loss: 0.049394\n",
      "Epoch 1, Batch 8 [2/2] 모델 업데이트 완료.\n",
      "\n",
      "==================== Epoch 2/15 ====================\n",
      "Epoch 2, Batch 1 [1/2] 위상 업데이트 완료. Loss: 0.038773\n",
      "Epoch 2, Batch 1 [2/2] 모델 업데이트 완료.\n",
      "Epoch 2, Batch 2 [1/2] 위상 업데이트 완료. Loss: 0.371331\n",
      "Epoch 2, Batch 2 [2/2] 모델 업데이트 완료.\n",
      "Epoch 2, Batch 3 [1/2] 위상 업데이트 완료. Loss: 0.464088\n",
      "Epoch 2, Batch 3 [2/2] 모델 업데이트 완료.\n",
      "Epoch 2, Batch 4 [1/2] 위상 업데이트 완료. Loss: 0.511777\n",
      "Epoch 2, Batch 4 [2/2] 모델 업데이트 완료.\n",
      "Epoch 2, Batch 5 [1/2] 위상 업데이트 완료. Loss: 0.364322\n",
      "Epoch 2, Batch 5 [2/2] 모델 업데이트 완료.\n",
      "Epoch 2, Batch 6 [1/2] 위상 업데이트 완료. Loss: 0.233395\n",
      "Epoch 2, Batch 6 [2/2] 모델 업데이트 완료.\n",
      "Epoch 2, Batch 7 [1/2] 위상 업데이트 완료. Loss: 0.221907\n",
      "Epoch 2, Batch 7 [2/2] 모델 업데이트 완료.\n",
      "Epoch 2, Batch 8 [1/2] 위상 업데이트 완료. Loss: 0.064329\n",
      "Epoch 2, Batch 8 [2/2] 모델 업데이트 완료.\n",
      "\n",
      "==================== Epoch 3/15 ====================\n",
      "Epoch 3, Batch 1 [1/2] 위상 업데이트 완료. Loss: 0.171499\n",
      "Epoch 3, Batch 1 [2/2] 모델 업데이트 완료.\n",
      "Epoch 3, Batch 2 [1/2] 위상 업데이트 완료. Loss: 0.047819\n",
      "Epoch 3, Batch 2 [2/2] 모델 업데이트 완료.\n",
      "Epoch 3, Batch 3 [1/2] 위상 업데이트 완료. Loss: 0.196815\n",
      "Epoch 3, Batch 3 [2/2] 모델 업데이트 완료.\n",
      "Epoch 3, Batch 4 [1/2] 위상 업데이트 완료. Loss: 0.031278\n",
      "Epoch 3, Batch 4 [2/2] 모델 업데이트 완료.\n",
      "Epoch 3, Batch 5 [1/2] 위상 업데이트 완료. Loss: 0.035209\n",
      "Epoch 3, Batch 5 [2/2] 모델 업데이트 완료.\n",
      "Epoch 3, Batch 6 [1/2] 위상 업데이트 완료. Loss: 0.037680\n",
      "Epoch 3, Batch 6 [2/2] 모델 업데이트 완료.\n",
      "Epoch 3, Batch 7 [1/2] 위상 업데이트 완료. Loss: 0.076898\n",
      "Epoch 3, Batch 7 [2/2] 모델 업데이트 완료.\n",
      "Epoch 3, Batch 8 [1/2] 위상 업데이트 완료. Loss: 0.074889\n",
      "Epoch 3, Batch 8 [2/2] 모델 업데이트 완료.\n",
      "\n",
      "==================== Epoch 4/15 ====================\n",
      "Epoch 4, Batch 1 [1/2] 위상 업데이트 완료. Loss: 0.032447\n",
      "Epoch 4, Batch 1 [2/2] 모델 업데이트 완료.\n",
      "Epoch 4, Batch 2 [1/2] 위상 업데이트 완료. Loss: 0.054283\n",
      "Epoch 4, Batch 2 [2/2] 모델 업데이트 완료.\n",
      "Epoch 4, Batch 3 [1/2] 위상 업데이트 완료. Loss: 0.074547\n",
      "Epoch 4, Batch 3 [2/2] 모델 업데이트 완료.\n",
      "Epoch 4, Batch 4 [1/2] 위상 업데이트 완료. Loss: 0.040436\n",
      "Epoch 4, Batch 4 [2/2] 모델 업데이트 완료.\n",
      "Epoch 4, Batch 5 [1/2] 위상 업데이트 완료. Loss: 0.036976\n",
      "Epoch 4, Batch 5 [2/2] 모델 업데이트 완료.\n",
      "Epoch 4, Batch 6 [1/2] 위상 업데이트 완료. Loss: 0.024752\n",
      "Epoch 4, Batch 6 [2/2] 모델 업데이트 완료.\n",
      "Epoch 4, Batch 7 [1/2] 위상 업데이트 완료. Loss: 0.040763\n",
      "Epoch 4, Batch 7 [2/2] 모델 업데이트 완료.\n",
      "Epoch 4, Batch 8 [1/2] 위상 업데이트 완료. Loss: 0.224237\n",
      "Epoch 4, Batch 8 [2/2] 모델 업데이트 완료.\n",
      "\n",
      "==================== Epoch 5/15 ====================\n",
      "Epoch 5, Batch 1 [1/2] 위상 업데이트 완료. Loss: 0.076464\n",
      "Epoch 5, Batch 1 [2/2] 모델 업데이트 완료.\n",
      "Epoch 5, Batch 2 [1/2] 위상 업데이트 완료. Loss: 0.186034\n",
      "Epoch 5, Batch 2 [2/2] 모델 업데이트 완료.\n",
      "Epoch 5, Batch 3 [1/2] 위상 업데이트 완료. Loss: 0.215727\n",
      "Epoch 5, Batch 3 [2/2] 모델 업데이트 완료.\n",
      "Epoch 5, Batch 4 [1/2] 위상 업데이트 완료. Loss: 0.061529\n",
      "Epoch 5, Batch 4 [2/2] 모델 업데이트 완료.\n",
      "Epoch 5, Batch 5 [1/2] 위상 업데이트 완료. Loss: 0.039542\n",
      "Epoch 5, Batch 5 [2/2] 모델 업데이트 완료.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 83\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m [2/2] 모델 업데이트 완료.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     82\u001b[39m temp = phase_tensors.clone()\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m output = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.numpy()[\u001b[32m0\u001b[39m]\n\u001b[32m     84\u001b[39m output = (output - np.min(output)) / (np.max(output) - np.min(output))\n\u001b[32m     85\u001b[39m output = output * \u001b[32m255\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from pytorch_msssim import ssim, ms_ssim # Multi-Scale SSIM이 더 성능이 좋을 수 있습니다.\n",
    "import torch.nn.functional as F\n",
    "\n",
    "NUM_EPOCHS = 15 # 전체 데이터셋을 몇 번 반복할지\n",
    "lam = 0.532e-6\n",
    "dx = 12.5e-6\n",
    "z = 100e-3\n",
    "\n",
    "lam = torch.tensor(lam).cuda()\n",
    "dx = torch.tensor(dx).cuda()\n",
    "z = torch.tensor(z).cuda()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\n{'='*20} Epoch {epoch + 1}/{NUM_EPOCHS} {'='*20}\")\n",
    "    \n",
    "        # data_loader에서 미니배치 단위로 데이터를 가져옴\n",
    "    for i, (target_amplitudes, phase_tensors, image_paths) in enumerate(data_loader):\n",
    "        \n",
    "        # --- 단계 1: 위상 업데이트 -\n",
    "        model.eval()\n",
    "        optimizer_phase.zero_grad()\n",
    "        \n",
    "        # U-Net 모델은 배치 입력을 처리할 수 있도록 수정됨\n",
    "        prediction_for_phase = model(phase_tensors)\n",
    "\n",
    "        field = torch.exp(1j * prediction_for_phase)\n",
    "        propagated_field = fresnel_cuda(field, lam, dx, z)\n",
    "        prediction_for_phase = torch.abs(propagated_field)\n",
    "        prediction_for_phase = prediction_for_phase/torch.max(prediction_for_phase).item()\n",
    "\n",
    "        loss_phase = loss_fn(s1 * prediction_for_phase, target_amplitudes)\n",
    "        loss_phase.backward()\n",
    "        optimizer_phase.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}, Batch {i+1} [1/2] 위상 업데이트 완료. Loss: {loss_phase.item():.6f}\")\n",
    "\n",
    "        # --- 단계 2: 모델 업데이트 ---\n",
    "        # 이 단계에서는 미니배치의 각 이미지에 대해 물리적 실험을 반복해야 함\n",
    "        \n",
    "        captured_amplitudes_batch = []\n",
    "        # 배치 내 각 샘플에 대해 SLM 띄우고 촬영\n",
    "        for j in range(len(image_paths)):\n",
    "            phase_to_display = phase_tensors[j]\n",
    "            \n",
    "            save_phase_as_image(phase_to_display, 'test.png')\n",
    "            \n",
    "            slm_process = subprocess.Popen(['python', 'test.py'])\n",
    "            time.sleep(2)\n",
    "            \n",
    "            # ‼️ 실제 카메라 촬영 로직\n",
    "            camera = Lucam()\n",
    "            capture = camera.TakeSnapshot()\n",
    "            capture = cv2.resize(capture, dsize=(N, N))\n",
    "            cv2.imwrite('captured_image.png', capture)\n",
    "            \n",
    "            slm_process.terminate()\n",
    "            slm_process.wait()\n",
    "\n",
    "            captured_amp = torch.sqrt(load_and_preprocess_image('captured_image.png'))\n",
    "            captured_amplitudes_batch.append(captured_amp)\n",
    "        \n",
    "        # 촬영된 이미지들을 하나의 배치 텐서로 결합\n",
    "        captured_amplitudes = torch.stack(captured_amplitudes_batch)\n",
    "        \n",
    "        # 모델 학습\n",
    "        model.train()\n",
    "        optimizer_model.zero_grad()\n",
    "        \n",
    "        # phase_tensors는 업데이트되었지만, 모델 학습에는 이전 상태를 사용해야 함\n",
    "        prediction_for_model = model(phase_tensors.detach())\n",
    "\n",
    "        field = torch.exp(1j * prediction_for_model)\n",
    "        propagated_field = fresnel_cuda(field, lam, dx, z)\n",
    "        prediction_for_model = torch.abs(propagated_field)\n",
    "        prediction_for_model = prediction_for_model / torch.max(prediction_for_model).item()\n",
    "\n",
    "        loss_model = loss_fn(s2 * prediction_for_model, captured_amplitudes.cuda())\n",
    "        loss_model.backward()\n",
    "        optimizer_model.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}, Batch {i+1} [2/2] 모델 업데이트 완료.\")\n",
    "        temp = phase_tensors.clone()\n",
    "        output = model(temp.detach()).detach().cpu().numpy()[0]\n",
    "        output = (output - np.min(output)) / (np.max(output) - np.min(output))\n",
    "        output = output * 255\n",
    "        Image.fromarray(output.astype('uint8')).save('output.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9948be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9336, 0.3582, 0.7935, 0.0520, 0.3762, 0.8230, 0.8240, 0.7717, 0.0079,\n",
       "         0.2563],\n",
       "        [0.9462, 0.2194, 0.8983, 0.5424, 0.2604, 0.7501, 0.1395, 0.1190, 0.3600,\n",
       "         0.1297],\n",
       "        [0.3989, 0.1994, 0.9521, 0.5441, 0.9915, 0.8992, 0.0383, 0.1927, 0.6817,\n",
       "         0.8282],\n",
       "        [0.1613, 0.1447, 0.6904, 0.1973, 0.8128, 0.0421, 0.7949, 0.5161, 0.1538,\n",
       "         0.4465],\n",
       "        [0.2018, 0.4343, 0.7569, 0.5306, 0.7159, 0.2957, 0.6866, 0.0284, 0.2571,\n",
       "         0.9168],\n",
       "        [0.0722, 0.5894, 0.6778, 0.3464, 0.1135, 0.7081, 0.0522, 0.5975, 0.4147,\n",
       "         0.4051],\n",
       "        [0.4297, 0.0296, 0.8246, 0.1053, 0.2656, 0.4284, 0.0789, 0.7853, 0.7905,\n",
       "         0.3956],\n",
       "        [0.5438, 0.5039, 0.9148, 0.5283, 0.7852, 0.2799, 0.8295, 0.6605, 0.5125,\n",
       "         0.3032],\n",
       "        [0.1538, 0.1275, 0.0366, 0.4837, 0.3076, 0.3640, 0.7123, 0.4583, 0.7257,\n",
       "         0.0591],\n",
       "        [0.5978, 0.1666, 0.9902, 0.2688, 0.7349, 0.1601, 0.3599, 0.6982, 0.3267,\n",
       "         0.9377]], requires_grad=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand((10,10), requires_grad=True)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1317382a",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.max(torch.abs(a)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03fcbdf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c를 통해 역전파 후 a의 그래디언트:\n",
      "tensor([[0.3333, 0.3333, 0.3333],\n",
      "        [0.3333, 0.3333, 0.3333]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# requires_grad=True로 설정하여 그래디언트 추적\n",
    "a = torch.ones(2, 3, requires_grad=True)\n",
    "\n",
    "# 2. .item()을 사용한 경우 (그래디언트 흐름이 끊김)\n",
    "b = torch.max(torch.abs(a)).item()\n",
    "\n",
    "c = torch.max(torch.abs(a))\n",
    "loss = c * 2\n",
    "\n",
    "# 그래디언트 계산 예시\n",
    "# c는 연산 그래프에 연결되어 있으므로 역전파 가능\n",
    "loss.backward()\n",
    "\n",
    "print(\"c를 통해 역전파 후 a의 그래디언트:\")\n",
    "print(a.grad) # a에 그래디언트가 계산됨\n",
    "\n",
    "# b는 파이썬 숫자이므로 역전파의 시작점이 될 수 없음\n",
    "# 만약 loss = b * 2 라고 한 뒤 loss.backward()를 시도하면 에러 발생"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "holo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
