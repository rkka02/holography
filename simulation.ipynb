{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e69e88e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57506165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = np.zeros((600,600))\n",
    "cv2.imwrite('dataset/zeros.png', pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a50adf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "N = 224\n",
    "random_phase = np.random.rand(4*N, 4*N) * 2 * np.pi\n",
    "def create_speckle(phase, lam=0.532e-6, f1=0.20, f2=0.10):\n",
    "    N   = phase.shape[0]\n",
    "    Np  = 4 * N                    # íŒ¨ë”©ëœ ê²©ì í¬ê¸° # 4 * 224 = 896\n",
    "    pad = (Np - N)//2              # (896 - 224)//2 = 336\n",
    "    \n",
    "    # 1) ì…ë ¥ë©´\n",
    "    M = np.exp(1j * phase)\n",
    "    M = np.pad(M, pad_width=pad, mode='constant', constant_values=0)\n",
    "    \n",
    "    # 2) í‘¸ë¦¬ì—ë©´ ë¬´ì‘ìœ„ ìœ„ìƒ ë””í“¨ì €\n",
    "    D = np.exp(1j * random_phase)          # ìœ„ìƒë§Œ ê°€ì§„ ë””í“¨ì €\n",
    "    \n",
    "    # 3) 1ì°¨ FFT (í‘¸ë¦¬ì—ë©´)\n",
    "    F = np.fft.fftshift(np.fft.fft2(np.fft.fftshift(M))) * D\n",
    "    \n",
    "    # 4) 2ì°¨ FFT (ì˜ìƒë©´)\n",
    "    U = np.fft.ifftshift(np.fft.ifft2(np.fft.ifftshift(F)))\n",
    "    \n",
    "    # ë°°ìœ¨ ë³´ì • & ë’¤ì§‘ê¸°\n",
    "    U *= (1/(lam**2 * f1 * f2))\n",
    "    U = np.flip(U, axis=(0, 1))\n",
    "    \n",
    "    # 5) ê²°ê³¼ í¬ë¡­ (ì›ë³¸ë³´ë‹¤ 2ë°° ë„“ê²Œ ë³´ê¸°)\n",
    "    out_size = 2*N           # ì˜ˆ: 2NÃ—2N ROI # 2*224=448\n",
    "    start = (Np - out_size)//2\n",
    "    I = np.abs(U[start:start+out_size, start:start+out_size])**2\n",
    "    \n",
    "    # í•„ìš”í•˜ë©´ ë‹¤ì‹œ 0.5ë°° ì¶•ì†Œ(ì‹¤ì œ ë°°ìœ¨) í›„ ë¶™ì—¬ë„£ê¸°\n",
    "    I_small = cv2.resize(I, dsize=(N, N), interpolation=cv2.INTER_AREA)\n",
    "    I_small = I_small / np.max(I_small[N//4:3*N//4, N//4:3*N//4])\n",
    "    return I_small\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73cf687b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:08<00:00, 12.35it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "path = 'dataset/train/phase'\n",
    "vmax =  2\n",
    "for file in tqdm(os.listdir(path)):\n",
    "    phase = Image.open(os.path.join(path, file)).convert('L')\n",
    "    phase = np.array(phase)\n",
    "    phase = phase / 255 * 2 * np.pi\n",
    "    phase = cv2.resize(phase, dsize=(224, 224))\n",
    "    speckle = create_speckle(phase)\n",
    "    speckle = speckle / vmax * 225\n",
    "    Image.fromarray(speckle.astype('uint8')).save(f'dataset/train/speckle/{file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27d11d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1ë‹¨ê³„: ì „ì²´ ë°ì´í„°ì…‹ì˜ 99.9 í¼ì„¼íƒ€ì¼ ê°’ì„ ê³„ì‚°í•©ë‹ˆë‹¤...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:08<00:00, 12.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ê³„ì‚°ëœ 99.9 í¼ì„¼íƒ€ì¼ (vmax): 1.9363751369183269\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# create_speckle í•¨ìˆ˜ê°€ ì •ì˜ë˜ì–´ ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.\n",
    "# ì˜ˆì‹œ: def create_speckle(phase): ... return speckle_pattern\n",
    "\n",
    "# --- ê²½ë¡œ ì„¤ì • ---\n",
    "path = 'dataset/train/phase'\n",
    "\n",
    "all_speckle_values = []\n",
    "\n",
    "print(\"1ë‹¨ê³„: ì „ì²´ ë°ì´í„°ì…‹ì˜ 99.9 í¼ì„¼íƒ€ì¼ ê°’ì„ ê³„ì‚°í•©ë‹ˆë‹¤...\")\n",
    "for file in tqdm(os.listdir(path)):\n",
    "    # ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  phase ë§µìœ¼ë¡œ ë³€í™˜\n",
    "    phase = Image.open(os.path.join(path, file)).convert('L')\n",
    "    phase = np.array(phase)\n",
    "    phase = phase / 255.0 * 2 * np.pi\n",
    "    phase = cv2.resize(phase, dsize=(224, 224))\n",
    "\n",
    "    # ìŠ¤í˜í´ ìƒì„± (ì´ í•¨ìˆ˜ëŠ” ì´ë¯¸ ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤)\n",
    "    speckle = create_speckle(phase)\n",
    "\n",
    "    # ìƒì„±ëœ ìŠ¤í˜í´ ê°’ë“¤ì„ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ì— ëª¨ë‘ ì¶”ê°€\n",
    "    all_speckle_values.extend(speckle.flatten())\n",
    "\n",
    "# ëª¨ë“  ìŠ¤í˜í´ ê°’ë“¤ ì¤‘ì—ì„œ 99.9 í¼ì„¼íƒ€ì¼ ê³„ì‚°\n",
    "# ë°ì´í„°ì…‹ì´ ë§¤ìš° í¬ë©´ ì´ ë¶€ë¶„ì—ì„œ ë©”ëª¨ë¦¬ë¥¼ ë§ì´ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "vmax_p999 = np.percentile(all_speckle_values, 99.99)\n",
    "\n",
    "print(f\"\\nê³„ì‚°ëœ 99.9 í¼ì„¼íƒ€ì¼ (vmax): {vmax_p999}\")\n",
    "\n",
    "# ì´ì œ ì´ vmax_p999 ê°’ì„ 2ë‹¨ê³„ì—ì„œ ì‚¬ìš©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8664374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def get_slm_grey_level(desired_phase, calibration_data):\n",
    "\n",
    "    if not calibration_data:\n",
    "        raise ValueError(\"SLM calibration data cannot be empty.\")\n",
    "    \n",
    "    # ê·¸ë ˆì´ ë ˆë²¨ ë°°ì—´ (0, 1, 2, ..., 255)\n",
    "    grey_levels = np.arange(len(calibration_data))\n",
    "\n",
    "    # interp1d í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë³´ê°„ í•¨ìˆ˜ ìƒì„±\n",
    "    # x: ìœ„ìƒ ê°’ (calibration_data), y: ê·¸ë ˆì´ ë ˆë²¨ (grey_levels)\n",
    "    # kind='linear': ì„ í˜• ë³´ê°„\n",
    "    # bounds_error=False: ì…ë ¥ ìœ„ìƒì´ calibration_data ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ë„ ì—ëŸ¬ ë°œìƒ ì•ˆ í•¨\n",
    "    # fill_value=(grey_levels[0], grey_levels[-1]): ë²”ìœ„ ë°–ì˜ ê°’ì€ ìµœì†Œ/ìµœëŒ€ ê·¸ë ˆì´ ë ˆë²¨ë¡œ í´ë¨í”„\n",
    "    interpolation_function = interp1d(\n",
    "        calibration_data,\n",
    "        grey_levels,\n",
    "        kind='linear',\n",
    "        bounds_error=False,\n",
    "        fill_value=(grey_levels[0], grey_levels[-1])\n",
    "    )\n",
    "\n",
    "    # ì›í•˜ëŠ” ìœ„ìƒì— í•´ë‹¹í•˜ëŠ” ê·¸ë ˆì´ ë ˆë²¨ ê³„ì‚°\n",
    "    interpolated_grey_level = interpolation_function(desired_phase)\n",
    "\n",
    "    # ê²°ê³¼ë¥¼ ê°€ì¥ ê°€ê¹Œìš´ ì •ìˆ˜ë¡œ ë°˜ì˜¬ë¦¼í•˜ê³ , ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜\n",
    "    # .item()ì€ numpy ë°°ì—´ì´ ì•„ë‹Œ ìŠ¤ì¹¼ë¼ ê°’ì„ ë°˜í™˜í•˜ë„ë¡ í•©ë‹ˆë‹¤.\n",
    "    return int(np.round(interpolated_grey_level).item())\n",
    "\n",
    "loaded_data = []\n",
    "with open('LUT.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        stripped_line = line.strip() # ê³µë°±(ì¤„ë°”ê¿ˆ í¬í•¨) ì œê±°\n",
    "        if stripped_line: # ë¹ˆ ì¤„ì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ ì²˜ë¦¬\n",
    "            loaded_data.append(float(stripped_line))\n",
    "            \n",
    "grey_levels = np.arange(len(loaded_data))\n",
    "\n",
    "phase_to_grey_level_interpolator = interp1d(\n",
    "    loaded_data,\n",
    "    grey_levels,\n",
    "    kind='linear',\n",
    "    bounds_error=False,\n",
    "    fill_value=(grey_levels[0], grey_levels[-1])\n",
    ")\n",
    "\n",
    "grey_to_phase_level_interpolator = interp1d(\n",
    "    grey_levels,\n",
    "    loaded_data,\n",
    "    kind='linear',\n",
    "    bounds_error=False,\n",
    "    fill_value=(grey_levels[0], grey_levels[-1])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3d15bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# --- ê¸°ë³¸ ì„¤ì • (ì´ì „ê³¼ ë™ì¼) ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "N = 600\n",
    "LEARNING_RATE_MODEL = 1e-4\n",
    "LEARNING_RATE_PHASE = 1e-3\n",
    "\n",
    "\n",
    "# --- ğŸŒŸ ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜ ğŸŒŸ ---\n",
    "class SpeckleDataset(Dataset):\n",
    "    def __init__(self, phase_dir, speckle_dir):\n",
    "        # ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°\n",
    "        self.phase_paths = sorted(os.listdir(phase_dir))\n",
    "        self.speckle_paths = sorted(os.listdir(speckle_dir))\n",
    "\n",
    "        self.phase_list = []\n",
    "        self.speckle_list = []\n",
    "\n",
    "        # ê° ì´ë¯¸ì§€ì— ëŒ€í•œ ìœ„ìƒì„ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬\n",
    "        for path in self.phase_paths:\n",
    "            phase = Image.open(os.path.join(phase_dir, path)).convert('L')\n",
    "            phase = np.array(phase)\n",
    "            \n",
    "            phase = cv2.resize(phase, dsize=(N, N))\n",
    "            phase = phase / np.max(phase) * 2 * np.pi\n",
    "            phase = np.clip(phase_to_grey_level_interpolator(phase), 0, 255).astype('uint8')\n",
    "            \n",
    "            phase = grey_to_phase_level_interpolator(phase)\n",
    "            # phase = np.pad(phase, pad_width=(2048-N)//2, mode='constant', constant_values=0)\n",
    "            self.phase_list.append(phase)\n",
    "        \n",
    "        for path in self.speckle_paths:\n",
    "            speckle = Image.open(os.path.join(speckle_dir, path)).convert('L')\n",
    "            speckle = np.array(speckle)\n",
    "            speckle = speckle / np.max(speckle)\n",
    "            # speckle = cv2.resize(speckle, dsize=(N, N))\n",
    "            self.speckle_list.append(speckle)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.phase_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        phase = self.phase_list[idx]\n",
    "        speckle = self.speckle_list[idx]\n",
    "        phase = torch.from_numpy(phase)\n",
    "        speckle = torch.from_numpy(speckle)\n",
    "        return phase, speckle\n",
    "    \n",
    "train_dataset = SpeckleDataset('dataset/diffuser/train/phase', 'dataset/diffuser/train/speckle')\n",
    "test_dataset = SpeckleDataset('dataset/diffuser/test/phase', 'dataset/diffuser/test/speckle')\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02656b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_msssim import ssim, ms_ssim # <--- ì´ ë¶€ë¶„ì„ ì¶”ê°€í•˜ì„¸ìš”\n",
    "import torch.nn.functional as F\n",
    "from skimage import feature\n",
    "\n",
    "# --- ê¸°ë³¸ ì„¤ì • (ì´ì „ê³¼ ë™ì¼) ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "N = 600\n",
    "LEARNING_RATE_MODEL = 1e-4\n",
    "LEARNING_RATE_PHASE = 1e-3\n",
    "\n",
    "import torch, math\n",
    "import torch.nn as nn\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â‘  ê³ ì • pupil ìƒì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def make_pupil(N, radius_px=10, y_shift_px=-10):\n",
    "    x = torch.arange(-N//2, N//2)\n",
    "    X, Y = torch.meshgrid(x, x, indexing='ij')\n",
    "    P = (((X+y_shift_px)**2 + Y**2) < radius_px**2).float()\n",
    "    return P          # (N,N) real, 0/1\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Residual DoubleConv â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "        )\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "        # ì…ë ¥Â·ì¶œë ¥ ì±„ë„ì´ ë‹¤ë¥´ë©´ 1Ã—1 í”„ë¡œì ì…˜\n",
    "        self.skip = nn.Identity() if in_ch == out_ch else nn.Conv2d(in_ch, out_ch, 1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.conv(x) + self.skip(x))\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Channel Attention (Squeeze & Excite) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "class SE(nn.Module):\n",
    "    def __init__(self, ch, r=8):\n",
    "        super().__init__()\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc   = nn.Sequential(nn.Linear(ch, ch//r, bias=False),\n",
    "                                  nn.ReLU(inplace=True),\n",
    "                                  nn.Linear(ch//r, ch, bias=False),\n",
    "                                  nn.Sigmoid())\n",
    "    def forward(self, x):\n",
    "        b,c,_,_ = x.shape\n",
    "        w = self.pool(x).view(b, c)\n",
    "        w = self.fc(w).view(b, c, 1, 1)\n",
    "        return x * w\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Deep U-Net â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "class DeepUNet(nn.Module):\n",
    "    def __init__(self, in_ch=1, out_ch=1, base=32):\n",
    "        super().__init__()\n",
    "        ch = base\n",
    "        # â”€ Encoder (5 ìŠ¤í…Œì´ì§€) â”€\n",
    "        self.e1 = ResBlock(in_ch,  ch)          # 224Ã—224\n",
    "        self.e2 = ResBlock(ch,     ch*2)        # 112Ã—112\n",
    "        self.e3 = ResBlock(ch*2,   ch*4)        # 56Ã—56\n",
    "        self.e4 = ResBlock(ch*4,   ch*8)        # 28Ã—28\n",
    "        self.e5 = ResBlock(ch*8,   ch*16)       # 14Ã—14\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "        # â”€ Bottleneck (7Ã—7) â”€\n",
    "        self.bottleneck = ResBlock(ch*16, ch*32)\n",
    "\n",
    "        # â”€ Decoder â”€\n",
    "        self.up5 = nn.ConvTranspose2d(ch*32, ch*16, 2, 2)  # 14Ã—14\n",
    "        self.d5  = ResBlock(ch*32, ch*16)\n",
    "        self.se5 = SE(ch*16)\n",
    "\n",
    "        self.up4 = nn.ConvTranspose2d(ch*16, ch*8, 2, 2)   # 28Ã—28\n",
    "        self.d4  = ResBlock(ch*16, ch*8)\n",
    "        self.se4 = SE(ch*8)\n",
    "\n",
    "        self.up3 = nn.ConvTranspose2d(ch*8, ch*4, 2, 2)    # 56Ã—56\n",
    "        self.d3  = ResBlock(ch*8, ch*4)\n",
    "        self.se3 = SE(ch*4)\n",
    "\n",
    "        self.up2 = nn.ConvTranspose2d(ch*4, ch*2, 2, 2)    # 112Ã—112\n",
    "        self.d2  = ResBlock(ch*4, ch*2)\n",
    "        self.se2 = SE(ch*2)\n",
    "\n",
    "        self.up1 = nn.ConvTranspose2d(ch*2, ch, 2, 2)      # 224Ã—224\n",
    "        self.d1  = ResBlock(ch*2, ch)\n",
    "        self.se1 = SE(ch)\n",
    "\n",
    "        # â”€ Output â”€\n",
    "        self.out_conv = nn.Conv2d(ch, out_ch, 1)\n",
    "        self.act = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        e1 = self.e1(x)\n",
    "        e2 = self.e2(self.pool(e1))\n",
    "        e3 = self.e3(self.pool(e2))\n",
    "        e4 = self.e4(self.pool(e3))\n",
    "        e5 = self.e5(self.pool(e4))\n",
    "\n",
    "        b  = self.bottleneck(self.pool(e5))\n",
    "\n",
    "        # Decoder with SE attention\n",
    "        d5 = self.se5(self.d5(torch.cat([self.up5(b), e5], dim=1)))\n",
    "        d4 = self.se4(self.d4(torch.cat([self.up4(d5), e4], dim=1)))\n",
    "        d3 = self.se3(self.d3(torch.cat([self.up3(d4), e3], dim=1)))\n",
    "        d2 = self.se2(self.d2(torch.cat([self.up2(d3), e2], dim=1)))\n",
    "        d1 = self.se1(self.d1(torch.cat([self.up1(d2), e1], dim=1)))\n",
    "\n",
    "        return self.act(self.out_conv(d1))\n",
    "\n",
    "\n",
    "class DeepDiffuser(nn.Module):\n",
    "    \"\"\"\n",
    "    CNNì„ ì‚¬ìš©í•˜ì—¬ Diffuserì˜ ë³µì¡í•œ ë¬¼ë¦¬ì  íŠ¹ì„±ì„ ëª¨ë¸ë§í•©ë‹ˆë‹¤.\n",
    "    ì´ ë„¤íŠ¸ì›Œí¬ëŠ” ìµœì¢…ì ìœ¼ë¡œ ë³µì†Œìˆ˜ í•„ë“œ(Complex Field) Hë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    def __init__(self, N=224, latent_channels=16):\n",
    "        super().__init__()\n",
    "        # ì´ ë„¤íŠ¸ì›Œí¬ëŠ” ê³ ì •ëœ íŒ¨í„´ì„ ìƒì„±í•˜ë¯€ë¡œ, ì…ë ¥ ëŒ€ì‹  í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°ë¡œ ì‹œì‘í•©ë‹ˆë‹¤.\n",
    "        # ì´ `initial_grid`ê°€ í•™ìŠµì„ í†µí•´ ë³µì¡í•œ íŒ¨í„´ìœ¼ë¡œ ë°œì „í•©ë‹ˆë‹¤.\n",
    "        self.initial_grid = nn.Parameter(torch.randn(1, latent_channels, N, N))\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(latent_channels, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            # ìµœì¢… ì¶œë ¥ì€ ë³µì†Œìˆ˜ì˜ ì‹¤ìˆ˜ë¶€(real)ì™€ í—ˆìˆ˜ë¶€(imag) 2ê°œì˜ ì±„ë„ì…ë‹ˆë‹¤.\n",
    "            nn.Conv2d(64, 2, kernel_size=1) \n",
    "        )\n",
    "\n",
    "    def forward(self):\n",
    "        # ë„¤íŠ¸ì›Œí¬ë¥¼ í†µê³¼ì‹œì¼œ 2ì±„ë„ ë§µ(ì‹¤ìˆ˜ë¶€, í—ˆìˆ˜ë¶€)ì„ ì–»ìŠµë‹ˆë‹¤.\n",
    "        complex_parts = self.net(self.initial_grid)\n",
    "        \n",
    "        real_part = complex_parts[:, 0, :, :]\n",
    "        imag_part = complex_parts[:, 1, :, :]\n",
    "        \n",
    "        # ë‘ ì±„ë„ì„ í•©ì³ ë³µì†Œìˆ˜ í…ì„œë¥¼ ë§Œë“­ë‹ˆë‹¤.\n",
    "        H = torch.complex(real_part, imag_part)\n",
    "        \n",
    "        # (ì„ íƒ ì‚¬í•­) ì•ˆì •ì ì¸ í•™ìŠµì„ ìœ„í•´ ì¶œë ¥ì˜ í¬ê¸°ë¥¼ ì œí•œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "        # ì˜ˆ: ì§„í­ì´ 1ì„ ë„˜ì§€ ì•Šë„ë¡ ì •ê·œí™”\n",
    "        H = H / (torch.max(torch.abs(H)) + 1e-8)\n",
    "        \n",
    "        return H.squeeze(0) # ë°°ì¹˜ ì°¨ì› ì œê±° (N, N)\n",
    "\n",
    "class SpeckleSimulator(nn.Module):\n",
    "    def __init__(self, N=600, lam=0.532e-6, f1=0.2, f2=0.1,\n",
    "                 radius_px=10, y_shift_px=-10):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.N = N\n",
    "        self.lam = lam\n",
    "        self.f1 = f1\n",
    "        self.f2 = f2\n",
    "        self.dx = 12.5e-6\n",
    "        \n",
    "        self.sim_size = 2048 * 2\n",
    "        self.pad_size = (self.sim_size - N) // 2 \n",
    "        \n",
    "        self.sim_size2 = int(self.sim_size*1.8/2)*2\n",
    "        self.pad_size2 = (self.sim_size2 - self.sim_size) // 2 \n",
    "        \n",
    "        x = np.linspace(-self.sim_size*self.dx//2, self.sim_size*self.dx//2, self.sim_size)\n",
    "        y = x\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        self.X = torch.from_numpy(X).cuda()\n",
    "        self.Y = torch.from_numpy(Y).cuda()\n",
    "        \n",
    "        alpha = torch.tensor(1.0)\n",
    "        self.alpha = nn.Parameter(alpha, requires_grad=True).cuda()\n",
    "        self.before_quad = torch.exp(1j * self.alpha * (self.X**2 + self.Y**2))\n",
    "        \n",
    "        # ì‹œìŠ¤í…œ ë°°ìœ¨ ê³„ì‚°\n",
    "        magnification = self.f2 / self.f1\n",
    "        \n",
    "        \n",
    "        # self.radius_px = radius_px\n",
    "        # self.y_shift_px = y_shift_px\n",
    "        \n",
    "        curvature = torch.ones(N, N) * torch.pi\n",
    "        self.curvature = nn.Parameter(curvature, requires_grad=True)\n",
    "        \n",
    "        diffuser_phase = torch.ones(self.sim_size, self.sim_size) * torch.pi\n",
    "        self.diffuser = nn.Parameter(diffuser_phase, requires_grad=True)\n",
    "        \n",
    "        diffuser_amplitude = torch.ones(self.sim_size, self.sim_size)\n",
    "        self.diffuser_amplitude = nn.Parameter(diffuser_amplitude, requires_grad=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.diffuser_net = DeepDiffuser(N=self.sim_size)\n",
    "\n",
    "    def forward(self, phase):\n",
    "        H = self.diffuser_amplitude * torch.exp(1j * self.diffuser) # Set diffuser as learnable parameter\n",
    "        # H = self.diffuser_net()  # Define diffuser \n",
    "        before_quad = torch.exp(1j * self.curvature)\n",
    "        M = torch.exp(1j * phase) * before_quad         # Define field after SLM\n",
    "        M = F.pad(M, pad=(self.pad_size, self.pad_size, self.pad_size, self.pad_size), \n",
    "                               mode='constant', value=0)     # Zero-Pad the field after SLM\n",
    "        \n",
    "        \n",
    "        f = torch.fft.fftshift(torch.fft.fft2(torch.fft.ifftshift(M))) * H # Fourier transform -> multiply diffuser\n",
    "        f = F.pad(f, pad=(self.pad_size2, self.pad_size2, self.pad_size2, self.pad_size2), \n",
    "                               mode='constant', value=0)     # Zero-Pad the field after SLM\n",
    "        U = torch.fft.fftshift(torch.fft.ifft2(torch.fft.ifftshift(f)))         # Inverse Fourier Transform\n",
    "        \n",
    "        out_size = 2048\n",
    "        start = (self.sim_size2 - out_size) // 2\n",
    "        \n",
    "        I = U[..., start:start+out_size, start:start+out_size]\n",
    "        I = torch.abs(I)**2                                                      # Take Intensity\n",
    "        I = I / torch.max(I).item()                                              # Normalization (?)\n",
    "        I = torch.flip(I, dims=[-1])                                             # Flip (because it is 4f system)\n",
    "        \n",
    "        return I\n",
    "\n",
    "model = SpeckleSimulator(N=N).cuda()\n",
    "# model = DeepUNet(in_ch=1, out_ch=1, base=32).cuda()\n",
    "model = model.cuda()\n",
    "\n",
    "loss_fn = torch.nn.L1Loss()\n",
    "s = torch.tensor(1.0, requires_grad=True)\n",
    "optimizer = torch.optim.Adam(list(model.parameters()) + [s], lr=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "802d1c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = Image.open('apple.png').convert('L')\n",
    "image = np.array(image)\n",
    "image = cv2.resize(image, dsize=(600,600))\n",
    "image = torch.from_numpy(image).type(torch.float).cuda()\n",
    "output = model(image.unsqueeze(0).unsqueeze(0))\n",
    "output = output.squeeze(0).squeeze(0).detach().cpu().numpy()\n",
    "output = np.real(output)\n",
    "output = output / np.max(output) * 255\n",
    "cv2.imwrite('output.png', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be6972bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, 2048)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ea8efce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(list(model.parameters()) + [s], lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30b08f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= Epoch : 0 =========\n",
      "Epoch 0, Train Loss 0.057889\n",
      "Epoch 0, Test Loss 0.048744\n",
      "========= Epoch : 1 =========\n",
      "Epoch 1, Train Loss 0.048478\n",
      "Epoch 1, Test Loss 0.045164\n",
      "========= Epoch : 2 =========\n",
      "Epoch 2, Train Loss 0.044974\n",
      "Epoch 2, Test Loss 0.042636\n",
      "========= Epoch : 3 =========\n",
      "Epoch 3, Train Loss 0.042726\n",
      "Epoch 3, Test Loss 0.041239\n",
      "========= Epoch : 4 =========\n",
      "Epoch 4, Train Loss 0.041304\n",
      "Epoch 4, Test Loss 0.039994\n",
      "========= Epoch : 5 =========\n",
      "Epoch 5, Train Loss 0.040240\n",
      "Epoch 5, Test Loss 0.039203\n",
      "========= Epoch : 6 =========\n",
      "Epoch 6, Train Loss 0.039398\n",
      "Epoch 6, Test Loss 0.038693\n",
      "========= Epoch : 7 =========\n",
      "Epoch 7, Train Loss 0.038721\n",
      "Epoch 7, Test Loss 0.038037\n",
      "========= Epoch : 8 =========\n",
      "Epoch 8, Train Loss 0.038108\n",
      "Epoch 8, Test Loss 0.037499\n",
      "========= Epoch : 9 =========\n",
      "Epoch 9, Train Loss 0.037474\n",
      "Epoch 9, Test Loss 0.037097\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 10\n",
    "for i in range(num_epoch):\n",
    "    print(f'========= Epoch : {i} =========')\n",
    "    model = model.train()\n",
    "    train_loss = []\n",
    "    for phase, speckle in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        phase = phase.type(torch.float32).cuda()\n",
    "        speckle = speckle.type(torch.float32).cuda()\n",
    "        \n",
    "        output = model(phase.unsqueeze(1))\n",
    "        output = output.squeeze(1)\n",
    "        \n",
    "        loss = loss_fn(s * output, speckle)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss.append(loss.item())\n",
    "    \n",
    "    print(f'Epoch {i}, Train Loss {np.mean(np.array(train_loss)):.6f}')\n",
    "    \n",
    "    model = model.eval()\n",
    "    test_loss = []\n",
    "    with torch.no_grad():\n",
    "        for phase, speckle in test_loader:\n",
    "            phase = phase.type(torch.float32).cuda()\n",
    "            speckle = speckle.type(torch.float32).cuda()\n",
    "        \n",
    "            output = model(phase.unsqueeze(1))\n",
    "            output = output.squeeze(1)\n",
    "            \n",
    "            loss = loss_fn(s * output, speckle)\n",
    "            test_loss.append(loss.item())\n",
    "        \n",
    "        print(f'Epoch {i}, Test Loss {np.mean(np.array(test_loss)):.6f}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "695514ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b7df60c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8382754 , 0.9443062 , 0.90308607, ..., 1.1463042 , 1.1608987 ,\n",
       "        1.0075988 ],\n",
       "       [0.9637756 , 1.1901566 , 1.2052312 , ..., 1.4637276 , 1.4466708 ,\n",
       "        1.1998686 ],\n",
       "       [0.9278644 , 1.2142792 , 1.2677054 , ..., 1.4628477 , 1.4509925 ,\n",
       "        1.1965402 ],\n",
       "       ...,\n",
       "       [1.0437094 , 1.3779941 , 1.4159017 , ..., 1.2128996 , 1.1790951 ,\n",
       "        0.9268981 ],\n",
       "       [1.0599117 , 1.3712713 , 1.4160833 , ..., 1.2321908 , 1.1915606 ,\n",
       "        0.95496184],\n",
       "       [0.88641095, 1.0794909 , 1.0947812 , ..., 0.94163746, 0.930267  ,\n",
       "        0.7953366 ]], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffuser = model.diffuser_amplitude.detach().cpu().numpy()\n",
    "diffuser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fcbef8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffuser = diffuser / np.max(diffuser) * 255\n",
    "cv2.imwrite('output.png', diffuser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "17431b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "path = r\"C:\\rkka_Projects\\physics\\dataset\\diffuser\\test\\phase\\1 (110).jpg\"\n",
    "image = Image.open(path).convert('L')\n",
    "image = np.array(image)\n",
    "image = cv2.resize(image, dsize=(N,N))\n",
    "phase = image / 255 * 2 * np.pi\n",
    "\n",
    "phase = torch.from_numpy(phase).cuda()\n",
    "phase = phase.type(torch.float32)\n",
    "phase = phase.unsqueeze(0).unsqueeze(0)\n",
    "output = model(phase)\n",
    "\n",
    "output = output.squeeze(0).squeeze(0)\n",
    "output = output.detach().cpu().numpy()\n",
    "output = output / np.max(output) * 255\n",
    "Image.fromarray(output.astype('uint8')).save('output.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "b3e8ff8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('apple.png').convert('L')\n",
    "image = np.array(image)\n",
    "image = cv2.resize(image, dsize=(224,224))\n",
    "phase = image / 255 * 2 * np.pi\n",
    "\n",
    "speckle = create_speckle(phase)\n",
    "speckle = speckle / np.max(speckle) * 225\n",
    "Image.fromarray(speckle.astype('uint8')).save(f'speckle.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877a913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "# =========================================================================================\n",
    "# ======================== ìˆ˜ì •ëœ IterativeInverter ëª¨ë¸ ====================================\n",
    "# =========================================================================================\n",
    "\n",
    "class IterativeInverter(nn.Module):\n",
    "    def __init__(self, forward_model: SpeckleSimulator):\n",
    "        super().__init__()\n",
    "        # 1. forward_modelì—ì„œ í•™ìŠµëœ ê³ ì • íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì ¸ì™€ bufferë¡œ ë“±ë¡í•©ë‹ˆë‹¤.\n",
    "        #    ì´ íŒŒë¼ë¯¸í„°ë“¤ì€ ë” ì´ìƒ í•™ìŠµë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
    "        self.N = forward_model.N\n",
    "        self.sim_size = forward_model.sim_size            # 4096\n",
    "        self.pad_size = forward_model.pad_size            # 1936\n",
    "        self.sim_size2 = forward_model.sim_size2          # 7372\n",
    "        self.pad_size2 = forward_model.pad_size2          # 1638\n",
    "        self.out_size = 2048  # SpeckleSimulatorì˜ crop í¬ê¸°\n",
    "\n",
    "        # ë””ë°”ì´ìŠ¤ ì¼ê´€ì„±ì„ ìœ„í•´ forward_modelì˜ íŒŒë¼ë¯¸í„°ë¡œë¶€í„° ë””ë°”ì´ìŠ¤ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "        self.device = forward_model.curvature.device\n",
    "        \n",
    "        # í•™ìŠµëœ íŒŒë¼ë¯¸í„°ë“¤ì„ bufferë¡œ ë“±ë¡\n",
    "        self.register_buffer('curvature', forward_model.curvature.detach())\n",
    "        self.register_buffer('diffuser_phase', forward_model.diffuser.detach())\n",
    "        self.register_buffer('diffuser_amplitude', forward_model.diffuser_amplitude.detach())\n",
    "        \n",
    "        # 2. Diffuserì˜ ì§„í­ê³¼ ìœ„ìƒì„ í¬í•¨í•˜ëŠ” ì‹œìŠ¤í…œ í•¨ìˆ˜ Hë¥¼ ë¯¸ë¦¬ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "        H = self.diffuser_amplitude * torch.exp(1j * self.diffuser_phase)\n",
    "        self.register_buffer('H', H)\n",
    "        \n",
    "        # 3. Hì˜ ì—­ì—°ì‚°ì— ì‚¬ìš©í•  ì¼¤ë ˆ ë³µì†Œìˆ˜(complex conjugate)ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "        epsilon = 1e-8\n",
    "        self.register_buffer('H_inv', torch.conj(self.H) / (torch.abs(self.H)**2 + epsilon))\n",
    "\n",
    "    def forward_propagation(self, input_phase):\n",
    "        \"\"\" ì…ë ¥ ìœ„ìƒ -> ì¶œë ¥ ë³µì†Œìˆ˜ í•„ë“œ (SpeckleSimulatorì˜ ê³¼ì •ì„ ì •í™•íˆ ì¬í˜„) \"\"\"\n",
    "        # 1. ì…ë ¥ë‹¨(SLM): ì…ë ¥ ìœ„ìƒê³¼ í•™ìŠµëœ ê³¡ë¥ (curvature)ì„ ê³±í•¨\n",
    "        before_quad = torch.exp(1j * self.curvature)\n",
    "        M = torch.exp(1j * input_phase) * before_quad\n",
    "        \n",
    "        # 2. ì²« ë²ˆì§¸ íŒ¨ë”©: N -> sim_size (224 -> 4096)\n",
    "        M_padded = F.pad(M, pad=(self.pad_size, self.pad_size, self.pad_size, self.pad_size), \n",
    "                         mode='constant', value=0)\n",
    "        \n",
    "        # 3. ì²« ë²ˆì§¸ ë Œì¦ˆ ë° Diffuser: FFT í›„ Hì™€ ê³±í•¨\n",
    "        f = torch.fft.fftshift(torch.fft.fft2(torch.fft.ifftshift(M_padded))) * self.H\n",
    "        \n",
    "        # 4. ë‘ ë²ˆì§¸ íŒ¨ë”©: sim_size -> sim_size2 (4096 -> 7372)\n",
    "        f_padded = F.pad(f, pad=(self.pad_size2, self.pad_size2, self.pad_size2, self.pad_size2), \n",
    "                         mode='constant', value=0)\n",
    "        \n",
    "        # 5. ë‘ ë²ˆì§¸ ë Œì¦ˆ: IFFT\n",
    "        U_large = torch.fft.fftshift(torch.fft.ifft2(torch.fft.ifftshift(f_padded)))\n",
    "        \n",
    "        # 6. ì¶œë ¥ë‹¨ í¬ë¡­: sim_size2 -> out_size (7372 -> 2048)\n",
    "        start = (self.sim_size2 - self.out_size) // 2\n",
    "        U_cropped = U_large[..., start:start+self.out_size, start:start+self.out_size]\n",
    "        \n",
    "        # 7. 4f ì‹œìŠ¤í…œ ë’¤ì§‘í˜(flip) ì ìš©\n",
    "        U_flipped = torch.flip(U_cropped, dims=[-1])\n",
    "        \n",
    "        # 8. ìµœì¢… ë‹¤ìš´ìƒ˜í”Œë§: out_size -> N (2048 -> 600)\n",
    "        #    interpolateëŠ” (B, C, H, W) 4D í…ì„œë¥¼ ìš”êµ¬í•˜ë¯€ë¡œ ì°¨ì› í™•ì¥ í›„ ì ìš©\n",
    "        U_real = U_flipped.real.unsqueeze(0).unsqueeze(0)\n",
    "        U_imag = U_flipped.imag.unsqueeze(0).unsqueeze(0)\n",
    "        U_real_small = F.interpolate(U_real, size=(self.N, self.N), mode='area')\n",
    "        U_imag_small = F.interpolate(U_imag, size=(self.N, self.N), mode='area')\n",
    "        \n",
    "        # ë‹¤ì‹œ ë³µì†Œìˆ˜ í•„ë“œë¡œ í•©ì¹˜ê³  ì°¨ì› ì¶•ì†Œ\n",
    "        output_field = torch.complex(U_real_small, U_imag_small).squeeze(0).squeeze(0)\n",
    "        \n",
    "        return output_field\n",
    "\n",
    "    def backward_propagation(self, output_field):\n",
    "        \"\"\" ì¶œë ¥ í•„ë“œ -> ì…ë ¥ í•„ë“œ (Forward Propagationì˜ ëª¨ë“  ê³¼ì •ì„ ì •í™•íˆ ì—­ìˆœìœ¼ë¡œ ìˆ˜í–‰) \"\"\"\n",
    "        # 8. ì—­-ë‹¤ìš´ìƒ˜í”Œë§: N -> out_size (600 -> 2048)\n",
    "        U_real_small = output_field.real.unsqueeze(0).unsqueeze(0)\n",
    "        U_imag_small = output_field.imag.unsqueeze(0).unsqueeze(0)\n",
    "        # ì—…ìƒ˜í”Œë§ì—ëŠ” 'bicubic' ì´ë‚˜ 'bilinear'ê°€ ì í•©\n",
    "        U_real_large = F.interpolate(U_real_small, size=(self.out_size, self.out_size), mode='bicubic', align_corners=False)\n",
    "        U_imag_large = F.interpolate(U_imag_small, size=(self.out_size, self.out_size), mode='bicubic', align_corners=False)\n",
    "        U_cropped = torch.complex(U_real_large, U_imag_large).squeeze(0).squeeze(0)\n",
    "\n",
    "        # 7. ì—­-ë’¤ì§‘í˜ ì ìš©\n",
    "        U_unflipped = torch.flip(U_cropped, dims=[-1])\n",
    "\n",
    "        # 6. ì—­-í¬ë¡­: out_sizeë¥¼ sim_size2 ìº”ë²„ìŠ¤ì— ë‹¤ì‹œ ì‚½ì…\n",
    "        start = (self.sim_size2 - self.out_size) // 2\n",
    "        U_large = torch.zeros(output_field.shape[:-2] + (self.sim_size2, self.sim_size2),\n",
    "                              dtype=torch.cfloat, device=output_field.device)\n",
    "        U_large[..., start:start+self.out_size, start:start+self.out_size] = U_unflipped\n",
    "        \n",
    "        # 5. ì—­-IFFT (-> FFT)\n",
    "        f_padded = torch.fft.fftshift(torch.fft.fft2(torch.fft.ifftshift(U_large)))\n",
    "\n",
    "        # 4. ì—­-ë‘ ë²ˆì§¸ íŒ¨ë”©: sim_size2 -> sim_size í¬ë¡­\n",
    "        f = f_padded[..., self.pad_size2:-self.pad_size2, self.pad_size2:-self.pad_size2]\n",
    "\n",
    "        # 3. ì—­-H ê³±ì…ˆ (-> H_inv ê³±ì…ˆ)\n",
    "        M_padded_fourier = f * self.H_inv\n",
    "        \n",
    "        # 2. ì—­-FFT (-> IFFT)\n",
    "        M_padded = torch.fft.ifftshift(torch.fft.ifft2(torch.fft.fftshift(M_padded_fourier)))\n",
    "        \n",
    "        # 1. ì—­-ì²« ë²ˆì§¸ íŒ¨ë”©: sim_size -> N í¬ë¡­\n",
    "        estimated_input_field = M_padded[..., self.pad_size:-self.pad_size, self.pad_size:-self.pad_size]\n",
    "\n",
    "        return estimated_input_field\n",
    "\n",
    "    def find_phase(self, target_image, iterations=50):\n",
    "        \"\"\" Gerchberg-Saxton ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ëª©í‘œ ì´ë¯¸ì§€ë¥¼ ë§Œë“œëŠ” ìµœì ì˜ ìœ„ìƒì„ ì°¾ìŠµë‹ˆë‹¤ \"\"\"\n",
    "        # ëª©í‘œ ì§„í­ ê³„ì‚° (0ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ê²ƒì„ ë°©ì§€)\n",
    "        target_amplitude = torch.sqrt(target_image.clamp(min=1e-8))\n",
    "        \n",
    "        # ì‹œì‘ì : ì…ë ¥ ìœ„ìƒì„ ëœë¤í•˜ê²Œ ì´ˆê¸°í™”\n",
    "        input_phase = (torch.rand_like(target_image) * 2 * torch.pi).to(self.device)\n",
    "\n",
    "        for _ in range(iterations):\n",
    "            # 1. [ì •ë°©í–¥] í˜„ì¬ ìœ„ìƒìœ¼ë¡œ ì¶œë ¥ í•„ë“œ ê³„ì‚°\n",
    "            output_field = self.forward_propagation(input_phase)\n",
    "            \n",
    "            # 2. [ì¶œë ¥ í‰ë©´ ì œì•½] ê³„ì‚°ëœ ìœ„ìƒì€ ìœ ì§€í•˜ë˜, ì§„í­ì€ ëª©í‘œ ì§„í­ìœ¼ë¡œ ê°•ì œ êµì²´\n",
    "            estimated_phase_at_output = torch.angle(output_field)\n",
    "            corrected_output_field = target_amplitude * torch.exp(1j * estimated_phase_at_output)\n",
    "            \n",
    "            # 3. [ì—­ë°©í–¥] ìˆ˜ì •ëœ ì¶œë ¥ í•„ë“œë¥¼ ì—­ì „íŒŒí•˜ì—¬ ì…ë ¥ í•„ë“œ ì¶”ì •\n",
    "            estimated_input_field = self.backward_propagation(corrected_output_field)\n",
    "            \n",
    "            # 4. [ì…ë ¥ í‰ë©´ ì œì•½] SLMì€ ìœ„ìƒë§Œ ì¡°ì ˆ ê°€ëŠ¥í•˜ë¯€ë¡œ, ì¶”ì •ëœ ì…ë ¥ í•„ë“œì˜ ìœ„ìƒë§Œ ì·¨í•¨\n",
    "            #    â˜…â˜… ì¤‘ìš” â˜…â˜…: ì¶”ì •ëœ í•„ë“œëŠ” (ì…ë ¥ ìœ„ìƒ + ê³¡ë¥ )ì´ë¯€ë¡œ, ê³¡ë¥ ì„ ë¹¼ì£¼ì–´ì•¼ ìˆœìˆ˜ ì…ë ¥ ìœ„ìƒì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "            input_phase = torch.angle(estimated_input_field) - self.curvature\n",
    "\n",
    "        return input_phase.detach() # ìµœì¢…ì ìœ¼ë¡œ ì°¾ì•„ë‚¸ ìœ„ìƒì„ ë°˜í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4d4fec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìµœì ì˜ ìœ„ìƒ íŒ¨í„´ì„ ì°¾ëŠ” ì¤‘... (ë°˜ë³µ ìµœì í™”)\n",
      "ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# í•™ìŠµëœ ëª¨ë¸ì„ 'forward_model'ë¡œ ì €ì¥\n",
    "forward_model = model.eval()\n",
    "\n",
    "# 1. í•™ìŠµëœ forward_modelë¡œ Inverter ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "inverter = IterativeInverter(forward_model).to(device)\n",
    "\n",
    "# 2. ëª©í‘œ ì´ë¯¸ì§€ ì¤€ë¹„ (ì´ì „ê³¼ ë™ì¼)\n",
    "target_img = Image.open('square.jpg').convert('L')\n",
    "target_img = np.array(target_img)\n",
    "target_ima = 255 - target_img\n",
    "target_img = cv2.resize(target_img, dsize=(600, 600))\n",
    "target_img = target_img / np.max(target_img) * 2 * np.pi\n",
    "target_image = torch.from_numpy(target_img).to(device, dtype=torch.float32)\n",
    "\n",
    "# 3. Inverterë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì  ìœ„ìƒ ì°¾ê¸°\n",
    "print(\"ìµœì ì˜ ìœ„ìƒ íŒ¨í„´ì„ ì°¾ëŠ” ì¤‘... (ë°˜ë³µ ìµœì í™”)\")\n",
    "# .find_phase() ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ë©´ ë‚´ë¶€ì ìœ¼ë¡œ ë£¨í”„ê°€ ëŒë©´ì„œ ìœ„ìƒì„ ì°¾ì•„ì¤ë‹ˆë‹¤.\n",
    "optimized_phase = inverter.find_phase(target_image, iterations=200)\n",
    "print(\"ì™„ë£Œ!\")\n",
    "\n",
    "# 4. ê²°ê³¼ ê²€ì¦: ì°¾ì€ ìœ„ìƒì„ ì›ë˜ì˜ forward_modelì— ë„£ì–´ ì‚¬ê³¼ê°€ ë‚˜ì˜¤ëŠ”ì§€ í™•ì¸\n",
    "with torch.no_grad():\n",
    "    # ì°¾ì€ ìœ„ìƒì„ ì •ë°©í–¥ ì‹œë®¬ë ˆì´í„°ì— ì…ë ¥\n",
    "    final_output = forward_model(optimized_phase.unsqueeze(0).unsqueeze(0))\n",
    "    final_output = final_output.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f2d3e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = optimized_phase.detach().cpu().numpy()\n",
    "temp = temp / np.max(temp) * 255\n",
    "Image.fromarray(temp.astype('uint8')).save('phase.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "641c5321",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = final_output.detach().cpu().numpy()\n",
    "temp = temp / np.max(temp) * 255\n",
    "Image.fromarray(temp.astype('uint8')).save('result.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "holo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
